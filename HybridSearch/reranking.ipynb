{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2e0bdb",
   "metadata": {},
   "source": [
    "# Reranking Hybrid Search Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc80207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_classic.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56168799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'langchain.txt'}, page_content='# LangChain Modules and Use Cases\\n\\nLangChain provides support for several main modules, each designed to address specific aspects of building applications with language models. For each module, LangChain offers examples to get started, how-to guides, reference documentation, and conceptual overviews. Below is a detailed breakdown of these modules, organized in increasing order of complexity.\\n\\n---\\n\\n## 1. Prompts'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 1. Prompts\\n\\nThe **Prompts** module focuses on prompt design, management, and optimization. It includes tools and utilities for:'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='- **Prompt Templates**: Construct templates that accept variables, few-shot exemplars, and structured prompts for different LLM APIs.\\n- **Utilities**: Support for prompt serialization, versioning, A/B testing, and guarding against prompt injection.\\n- **Best Practices**: Modular prompts, prompt unit tests, and automated prompt tuning workflows.\\n- **Real-World Examples**: Demonstrations of prompt scaffolding for classification, generation, translation, and role-based responses.\\n\\n---\\n\\n## 2. LLMs'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 2. LLMs\\n\\nThe **LLMs** module provides a consistent interface for interacting with various language model providers and flavors (e.g., text models, chat models, streaming outputs). Key features include:'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='- **Configuration Options**: Temperature/top-p, max tokens, streaming, and callback handlers.\\n- **Concurrency Controls**: Request caching and rate-limit backoff strategies.\\n- **Utilities**: Batching, prompt truncation, sampling diagnostics, and multi-model orchestration for ensemble or fallback strategies.\\n- **Usage Guidance**: Model selection, cost/performance tradeoffs, and safety filters.\\n\\n---\\n\\n## 3. Document Loaders'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 3. Document Loaders\\n\\nThe **Document Loaders** module standardizes the ingestion of data from diverse sources, including:'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='- **Supported Sources**: Local files (txt, md), PDFs, Word docs, HTML pages, email archives, cloud storage (S3, GCS, Azure), databases, and third-party connectors.\\n- **Features**: Parsing, text extraction, metadata preservation, OCR integration for scanned documents, chunking strategies, and encoding normalization.\\n- **Robustness**: Retry logic, provenance metadata, deduplication, and preprocessing hooks for cleaning, sanitization, and language detection.\\n\\n---\\n\\n## 4. Utils'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 4. Utils\\n\\nThe **Utils** module provides a broad collection of utilities to make LLM applications practical and composable. Examples include:'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='- **Code Execution**: Python REPL/tool execution for code generation workflows.\\n- **Embedding Helpers**: Tools for embedding generation and text normalization.\\n- **Knowledge Utilities**: Calculators, date/time parsers, and connectors to external services.\\n- **Other Utilities**: Logging, telemetry hooks, prompt caching, retry policies, and adapters for search engines and vector databases.\\n\\n---\\n\\n## 5. Chains'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 5. Chains\\n\\nThe **Chains** module models multi-step workflows that combine prompts, LLM calls, and utilities into reusable pipelines. Features include:'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='- **Flow Types**: Sequential chains, branching/conditional logic, parallel executions, and nested composition.\\n- **Error Handling**: Input/output schemas, instrumentation for latency and token usage, and tooling for unit testing and mocking.\\n- **Common Patterns**: Question-answering over documents, summarization pipelines, classification pipelines, and transform-then-generate flows.\\n\\n---\\n\\n## 6. Indexes'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 6. Indexes\\n\\nThe **Indexes** module focuses on organizing and querying large text corpora to augment LLM responses. It includes:\\n\\n- **Index Types**: Dense vector indexes (FAISS, HNSW, Annoy), sparse/inverted indexes, and hybrid strategies.\\n- **Utilities**: Index construction, incremental updates, sharding, persistence, and reindexing.\\n- **Retrieval Strategies**: k-NN, reranking, MMR, and techniques for long-document handling and chunk-level scoring.\\n\\n---\\n\\n## 7. Agents'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 7. Agents\\n\\nThe **Agents** module implements decision-making loops where an LLM chooses actions, executes tools, receives observations, and iterates until a termination condition is met. Features include:'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='- **Agent Frameworks**: Tool adapters (APIs, crawlers, calculators, databases), action schemas, and planner/executor patterns.\\n- **Safety Features**: Action whitelisting, step limits, sandboxing, and observation sanitization.\\n- **Examples**: Web search assistants, API-driven automation, task orchestration, and multi-tool reasoning flows.\\n\\n---\\n\\n## 8. Memory\\n\\nThe **Memory** module provides mechanisms for persisting and recalling conversational or task state across sessions. Key features include:'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='- **Implementations**: Ephemeral in-memory buffers, key-value stores, vectorized memories, and summary-based long-term memory.\\n- **Capabilities**: Memory retrieval strategies, staleness management, privacy-preserving storage, and configurable retention policies.\\n- **Patterns**: Summarizing long histories, selectively surfacing relevant facts, and combining memory with retrieval-augmented generation.\\n\\n---\\n\\n## 9. Chat'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 9. Chat\\n\\nThe **Chat** module focuses on message-oriented models and conversation protocols. It includes:'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='- **Message Handling**: Formalized message roles (system, user, assistant), conversation threading, partial/streamed message handling, and multi-turn context windows.\\n- **Integrations**: UI adapters, platform connectors (Slack, Teams, Webchat), role-based directives, and moderation/safety hooks.\\n- **Utilities**: Stitching chat transcripts into prompts, summarizing conversation context, and handling multi-user or multi-agent dialogues.\\n\\n---\\n\\n## 10. Evaluation & Monitoring'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 10. Evaluation & Monitoring\\n\\nThe **Evaluation & Monitoring** module provides tools for evaluating model outputs and monitoring application health. Features include:'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='- **Evaluation Pipelines**: Automated evaluation (human-in-the-loop, LM-based scoring, rubric-driven grading).\\n- **Testing**: Unit and integration test harnesses for chains/agents.\\n- **Metrics**: Quality, latency, cost, token usage, error rates, hallucination detection heuristics, and drift alerts.\\n- **Best Practices**: Continuous evaluation, synthetic test cases for regressions, and dashboards for observability and model benchmarking.\\n\\n---\\n\\n# Use Cases'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='---\\n\\n# Use Cases\\n\\nLangChain modules can be used in a variety of ways. Below are some of the common use cases supported by LangChain:\\n\\n### 1. Agents\\nAgents use a language model to interact with other tools. They can be used for grounded question/answering, interacting with APIs, or taking actions.\\n\\n### 2. Chatbots\\nLanguage models are ideal for creating chatbots due to their ability to produce coherent and contextually relevant text.'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='### 3. Data Augmented Generation\\nThis involves chains that interact with external data sources to fetch data for use in the generation step. Examples include summarization of long texts and question/answering over specific data sources.\\n\\n### 4. Question Answering\\nAnswering questions over specific documents, utilizing only the information in those documents to construct an answer.\\n\\n### 5. Summarization\\nSummarizing longer documents into shorter, more condensed chunks of information.'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='### 6. Evaluation\\nGenerative models are hard to evaluate with traditional metrics. LangChain provides prompts and chains to assist in evaluation using language models themselves.\\n\\n### 7. Generating Similar Examples\\nGenerating similar examples to a given input is a common use case for many applications. LangChain provides tools to assist with this.'),\n",
       " Document(metadata={'source': 'langchain.txt'}, page_content='### 8. Comparing Models\\nExperimenting with different prompts, models, and chains is a key part of developing the best possible application. The ModelLaboratory makes this process easier.\\n\\n---\\n\\nLangChain provides a comprehensive suite of tools and modules to simplify and accelerate the development of applications powered by language models. By leveraging these modules, developers can build robust, scalable, and efficient solutions tailored to their specific needs.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"langchain.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size= 500,\n",
    "    chunk_overlap = 50,\n",
    "    separators = [\"\\n\\n\", \"\\n\",\" \",\"\"]\n",
    ")\n",
    "\n",
    "docs = splitter.split_documents(documents)\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6e5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How can I use Langchain to build an application with memory and tools?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59aecdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_documents(docs, embedding=embedding_model)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\":8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353f80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"groq:openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9abe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "                            You are a helpful assistant. Your task is to rank the following documents from most to least relevant to the user's question.\n",
    "\n",
    "                            User's question: \"{question}\"  \n",
    "\n",
    "                            Documents:\n",
    "                            {documents}\n",
    "\n",
    "                            Instructions:\n",
    "                            - Think about the relevance of each document to the user's question.\n",
    "                            - Return a list of document indices in ranked order, starting from the most relavant.\n",
    "\n",
    "                            Output format: comma-seperated document indices (e.g., 2,1,3,0.....)                                    \n",
    "                                      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ffb4b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e7337483-8ce1-4a8f-9c9b-69262f45320f', metadata={'source': 'langchain.txt'}, page_content='# LangChain Modules and Use Cases\\n\\nLangChain provides support for several main modules, each designed to address specific aspects of building applications with language models. For each module, LangChain offers examples to get started, how-to guides, reference documentation, and conceptual overviews. Below is a detailed breakdown of these modules, organized in increasing order of complexity.\\n\\n---\\n\\n## 1. Prompts'),\n",
       " Document(id='7c634bb8-b38a-4d2c-8965-725f65d2c9ce', metadata={'source': 'langchain.txt'}, page_content='### 8. Comparing Models\\nExperimenting with different prompts, models, and chains is a key part of developing the best possible application. The ModelLaboratory makes this process easier.\\n\\n---\\n\\nLangChain provides a comprehensive suite of tools and modules to simplify and accelerate the development of applications powered by language models. By leveraging these modules, developers can build robust, scalable, and efficient solutions tailored to their specific needs.'),\n",
       " Document(id='b7f15fa3-d1d8-484c-a287-068d037e8af1', metadata={'source': 'langchain.txt'}, page_content='---\\n\\n# Use Cases\\n\\nLangChain modules can be used in a variety of ways. Below are some of the common use cases supported by LangChain:\\n\\n### 1. Agents\\nAgents use a language model to interact with other tools. They can be used for grounded question/answering, interacting with APIs, or taking actions.\\n\\n### 2. Chatbots\\nLanguage models are ideal for creating chatbots due to their ability to produce coherent and contextually relevant text.'),\n",
       " Document(id='7dba7e72-cdd4-4b6d-8b95-d53bc23df9bc', metadata={'source': 'langchain.txt'}, page_content='### 6. Evaluation\\nGenerative models are hard to evaluate with traditional metrics. LangChain provides prompts and chains to assist in evaluation using language models themselves.\\n\\n### 7. Generating Similar Examples\\nGenerating similar examples to a given input is a common use case for many applications. LangChain provides tools to assist with this.'),\n",
       " Document(id='581af320-3280-4b8a-81a5-08c10ce51123', metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 4. Utils\\n\\nThe **Utils** module provides a broad collection of utilities to make LLM applications practical and composable. Examples include:'),\n",
       " Document(id='5529430f-c3e1-4fda-985e-fc9235982fa8', metadata={'source': 'langchain.txt'}, page_content='- **Agent Frameworks**: Tool adapters (APIs, crawlers, calculators, databases), action schemas, and planner/executor patterns.\\n- **Safety Features**: Action whitelisting, step limits, sandboxing, and observation sanitization.\\n- **Examples**: Web search assistants, API-driven automation, task orchestration, and multi-tool reasoning flows.\\n\\n---\\n\\n## 8. Memory\\n\\nThe **Memory** module provides mechanisms for persisting and recalling conversational or task state across sessions. Key features include:'),\n",
       " Document(id='3bbf5717-f526-4728-b031-6d2de5093f75', metadata={'source': 'langchain.txt'}, page_content='- **Code Execution**: Python REPL/tool execution for code generation workflows.\\n- **Embedding Helpers**: Tools for embedding generation and text normalization.\\n- **Knowledge Utilities**: Calculators, date/time parsers, and connectors to external services.\\n- **Other Utilities**: Logging, telemetry hooks, prompt caching, retry policies, and adapters for search engines and vector databases.\\n\\n---\\n\\n## 5. Chains'),\n",
       " Document(id='61c86b41-2c97-49b3-bcfa-d008fccf6532', metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 5. Chains\\n\\nThe **Chains** module models multi-step workflows that combine prompts, LLM calls, and utilities into reusable pipelines. Features include:')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(query)\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "209a794a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['documents', 'question'], input_types={}, partial_variables={}, template='\\n                            You are a helpful assistant. Your task is to rank the following documents from most to least relevant to the user\\'s question.\\n\\n                            User\\'s question: \"{question}\"  \\n\\n                            Documents:\\n                            {documents}\\n\\n                            Instructions:\\n                            - Think about the relevance of each document to the user\\'s question.\\n                            - Return a list of document indices in ranked order, starting from the most relavant.\\n\\n                            Output format: comma-seperated document indices                                     \\n                                      ')\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000274EACB5FD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000274F1A6E950>, model_name='openai/gpt-oss-20b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94996835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. # LangChain Modules and Use Cases\\n\\nLangChain provides support for several main modules, each designed to address specific aspects of building applications with language models. For each module, LangChain offers examples to get started, how-to guides, reference documentation, and conceptual overviews. Below is a detailed breakdown of these modules, organized in increasing order of complexity.\\n\\n---\\n\\n## 1. Prompts\\n2. ### 8. Comparing Models\\nExperimenting with different prompts, models, and chains is a key part of developing the best possible application. The ModelLaboratory makes this process easier.\\n\\n---\\n\\nLangChain provides a comprehensive suite of tools and modules to simplify and accelerate the development of applications powered by language models. By leveraging these modules, developers can build robust, scalable, and efficient solutions tailored to their specific needs.\\n3. ---\\n\\n# Use Cases\\n\\nLangChain modules can be used in a variety of ways. Below are some of the common use cases supported by LangChain:\\n\\n### 1. Agents\\nAgents use a language model to interact with other tools. They can be used for grounded question/answering, interacting with APIs, or taking actions.\\n\\n### 2. Chatbots\\nLanguage models are ideal for creating chatbots due to their ability to produce coherent and contextually relevant text.\\n4. ### 6. Evaluation\\nGenerative models are hard to evaluate with traditional metrics. LangChain provides prompts and chains to assist in evaluation using language models themselves.\\n\\n### 7. Generating Similar Examples\\nGenerating similar examples to a given input is a common use case for many applications. LangChain provides tools to assist with this.\\n5. ---\\n\\n## 4. Utils\\n\\nThe **Utils** module provides a broad collection of utilities to make LLM applications practical and composable. Examples include:\\n6. - **Agent Frameworks**: Tool adapters (APIs, crawlers, calculators, databases), action schemas, and planner/executor patterns.\\n- **Safety Features**: Action whitelisting, step limits, sandboxing, and observation sanitization.\\n- **Examples**: Web search assistants, API-driven automation, task orchestration, and multi-tool reasoning flows.\\n\\n---\\n\\n## 8. Memory\\n\\nThe **Memory** module provides mechanisms for persisting and recalling conversational or task state across sessions. Key features include:\\n7. - **Code Execution**: Python REPL/tool execution for code generation workflows.\\n- **Embedding Helpers**: Tools for embedding generation and text normalization.\\n- **Knowledge Utilities**: Calculators, date/time parsers, and connectors to external services.\\n- **Other Utilities**: Logging, telemetry hooks, prompt caching, retry policies, and adapters for search engines and vector databases.\\n\\n---\\n\\n## 5. Chains\\n8. ---\\n\\n## 5. Chains\\n\\nThe **Chains** module models multi-step workflows that combine prompts, LLM calls, and utilities into reusable pipelines. Features include:'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_lines = [f\"{i+1}. {doc.page_content}\" for i, doc in enumerate(retrieved_docs)]\n",
    "formatted_docs = \"\\n\".join(doc_lines)\n",
    "\n",
    "formatted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c6d7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6,5,3,8,1,7,4,2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"question\": query, \"documents\": formatted_docs})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c21ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 2, 7, 0, 6, 3, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final order the documents should be after reranking\n",
    "\n",
    "indices = [int(x.strip())-1 for x in response.split(',') if x.strip().isnumeric()]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d21720f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5529430f-c3e1-4fda-985e-fc9235982fa8', metadata={'source': 'langchain.txt'}, page_content='- **Agent Frameworks**: Tool adapters (APIs, crawlers, calculators, databases), action schemas, and planner/executor patterns.\\n- **Safety Features**: Action whitelisting, step limits, sandboxing, and observation sanitization.\\n- **Examples**: Web search assistants, API-driven automation, task orchestration, and multi-tool reasoning flows.\\n\\n---\\n\\n## 8. Memory\\n\\nThe **Memory** module provides mechanisms for persisting and recalling conversational or task state across sessions. Key features include:'),\n",
       " Document(id='581af320-3280-4b8a-81a5-08c10ce51123', metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 4. Utils\\n\\nThe **Utils** module provides a broad collection of utilities to make LLM applications practical and composable. Examples include:'),\n",
       " Document(id='b7f15fa3-d1d8-484c-a287-068d037e8af1', metadata={'source': 'langchain.txt'}, page_content='---\\n\\n# Use Cases\\n\\nLangChain modules can be used in a variety of ways. Below are some of the common use cases supported by LangChain:\\n\\n### 1. Agents\\nAgents use a language model to interact with other tools. They can be used for grounded question/answering, interacting with APIs, or taking actions.\\n\\n### 2. Chatbots\\nLanguage models are ideal for creating chatbots due to their ability to produce coherent and contextually relevant text.'),\n",
       " Document(id='61c86b41-2c97-49b3-bcfa-d008fccf6532', metadata={'source': 'langchain.txt'}, page_content='---\\n\\n## 5. Chains\\n\\nThe **Chains** module models multi-step workflows that combine prompts, LLM calls, and utilities into reusable pipelines. Features include:'),\n",
       " Document(id='e7337483-8ce1-4a8f-9c9b-69262f45320f', metadata={'source': 'langchain.txt'}, page_content='# LangChain Modules and Use Cases\\n\\nLangChain provides support for several main modules, each designed to address specific aspects of building applications with language models. For each module, LangChain offers examples to get started, how-to guides, reference documentation, and conceptual overviews. Below is a detailed breakdown of these modules, organized in increasing order of complexity.\\n\\n---\\n\\n## 1. Prompts'),\n",
       " Document(id='3bbf5717-f526-4728-b031-6d2de5093f75', metadata={'source': 'langchain.txt'}, page_content='- **Code Execution**: Python REPL/tool execution for code generation workflows.\\n- **Embedding Helpers**: Tools for embedding generation and text normalization.\\n- **Knowledge Utilities**: Calculators, date/time parsers, and connectors to external services.\\n- **Other Utilities**: Logging, telemetry hooks, prompt caching, retry policies, and adapters for search engines and vector databases.\\n\\n---\\n\\n## 5. Chains'),\n",
       " Document(id='7dba7e72-cdd4-4b6d-8b95-d53bc23df9bc', metadata={'source': 'langchain.txt'}, page_content='### 6. Evaluation\\nGenerative models are hard to evaluate with traditional metrics. LangChain provides prompts and chains to assist in evaluation using language models themselves.\\n\\n### 7. Generating Similar Examples\\nGenerating similar examples to a given input is a common use case for many applications. LangChain provides tools to assist with this.'),\n",
       " Document(id='7c634bb8-b38a-4d2c-8965-725f65d2c9ce', metadata={'source': 'langchain.txt'}, page_content='### 8. Comparing Models\\nExperimenting with different prompts, models, and chains is a key part of developing the best possible application. The ModelLaboratory makes this process easier.\\n\\n---\\n\\nLangChain provides a comprehensive suite of tools and modules to simplify and accelerate the development of applications powered by language models. By leveraging these modules, developers can build robust, scalable, and efficient solutions tailored to their specific needs.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked_docs = [retrieved_docs[i] for i in indices if 0<=i<len(retrieved_docs)]\n",
    "\n",
    "reranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "165750a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Reranked results:\n",
      "\n",
      " Ranks 1: \n",
      " - **Agent Frameworks**: Tool adapters (APIs, crawlers, calculators, databases), action schemas, and planner/executor patterns.\n",
      "- **Safety Features**: Action whitelisting, step limits, sandboxing, and observation sanitization.\n",
      "- **Examples**: Web search assistants, API-driven automation, task orchestration, and multi-tool reasoning flows.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Memory\n",
      "\n",
      "The **Memory** module provides mechanisms for persisting and recalling conversational or task state across sessions. Key features include:\n",
      "\n",
      " Ranks 2: \n",
      " ---\n",
      "\n",
      "## 4. Utils\n",
      "\n",
      "The **Utils** module provides a broad collection of utilities to make LLM applications practical and composable. Examples include:\n",
      "\n",
      " Ranks 3: \n",
      " ---\n",
      "\n",
      "# Use Cases\n",
      "\n",
      "LangChain modules can be used in a variety of ways. Below are some of the common use cases supported by LangChain:\n",
      "\n",
      "### 1. Agents\n",
      "Agents use a language model to interact with other tools. They can be used for grounded question/answering, interacting with APIs, or taking actions.\n",
      "\n",
      "### 2. Chatbots\n",
      "Language models are ideal for creating chatbots due to their ability to produce coherent and contextually relevant text.\n",
      "\n",
      " Ranks 4: \n",
      " ---\n",
      "\n",
      "## 5. Chains\n",
      "\n",
      "The **Chains** module models multi-step workflows that combine prompts, LLM calls, and utilities into reusable pipelines. Features include:\n",
      "\n",
      " Ranks 5: \n",
      " # LangChain Modules and Use Cases\n",
      "\n",
      "LangChain provides support for several main modules, each designed to address specific aspects of building applications with language models. For each module, LangChain offers examples to get started, how-to guides, reference documentation, and conceptual overviews. Below is a detailed breakdown of these modules, organized in increasing order of complexity.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Prompts\n",
      "\n",
      " Ranks 6: \n",
      " - **Code Execution**: Python REPL/tool execution for code generation workflows.\n",
      "- **Embedding Helpers**: Tools for embedding generation and text normalization.\n",
      "- **Knowledge Utilities**: Calculators, date/time parsers, and connectors to external services.\n",
      "- **Other Utilities**: Logging, telemetry hooks, prompt caching, retry policies, and adapters for search engines and vector databases.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Chains\n",
      "\n",
      " Ranks 7: \n",
      " ### 6. Evaluation\n",
      "Generative models are hard to evaluate with traditional metrics. LangChain provides prompts and chains to assist in evaluation using language models themselves.\n",
      "\n",
      "### 7. Generating Similar Examples\n",
      "Generating similar examples to a given input is a common use case for many applications. LangChain provides tools to assist with this.\n",
      "\n",
      " Ranks 8: \n",
      " ### 8. Comparing Models\n",
      "Experimenting with different prompts, models, and chains is a key part of developing the best possible application. The ModelLaboratory makes this process easier.\n",
      "\n",
      "---\n",
      "\n",
      "LangChain provides a comprehensive suite of tools and modules to simplify and accelerate the development of applications powered by language models. By leveraging these modules, developers can build robust, scalable, and efficient solutions tailored to their specific needs.\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Reranked results:\")\n",
    "for i, doc in enumerate(reranked_docs, 1):\n",
    "    print(f\"\\n Ranks {i}: \\n {doc.page_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
