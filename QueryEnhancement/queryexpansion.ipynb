{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c80db80",
   "metadata": {},
   "source": [
    "# Query Enhancement -  Query Expansion Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c75b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_classic.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbac5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"langchain_crewai.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size= 500,\n",
    "    chunk_overlap = 50,\n",
    "    separators = [\"\\n\\n\", \"\\n\",\" \",\"\"]\n",
    ")\n",
    "\n",
    "docs = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23eb931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_documents(docs, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a02723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001DBCF8620D0>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type =\"mmr\",\n",
    "    search_kwargs= {\"k\":5}\n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd73342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant. Expand the following query to improve document retrieval by adding relevant synonyms, technical terms, and useful context.\\n\\nOriginal Query: \"{query}\"\\n\\nExpanded query:\\n')\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001DBF3867AD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001DBF3ABC390>, model_name='openai/gpt-oss-20b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are a helpful assistant. Expand the following query to improve document retrieval by adding relevant synonyms, technical terms, and useful context.\n",
    "\n",
    "Original Query: \"{query}\"\n",
    "\n",
    "Expanded query:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm= init_chat_model(\"groq:openai/gpt-oss-20b\")\n",
    "\n",
    "query_expansion_chain = query_expansion_prompt | llm | StrOutputParser()\n",
    "\n",
    "query_expansion_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "123d344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Expanded Query**\n",
      "\n",
      "```\n",
      "(\"analyze\" OR \"review\" OR \"evaluate\" OR \"scrutinize\" OR \"assess\")\n",
      "AND\n",
      "(\"papers\" OR \"articles\" OR \"publications\" OR \"journals\")\n",
      "AND\n",
      "(\"large number\" OR \"massive set\" OR \"thousands\" OR \"hundreds\" OR \"extensive collection\")\n",
      "AND\n",
      "(\"quickly\" OR \"rapidly\" OR \"efficiently\" OR \"fast\" OR \"in short time\")\n",
      "AND\n",
      "(\"text mining\" OR \"natural language processing\" OR \"machine learning\" OR\n",
      " \"topic modeling\" OR \"LDA\" OR \"BERT\" OR \"transformer\" OR \"embedding\" OR\n",
      " \"semantic analysis\" OR \"document clustering\" OR \"document classification\" OR\n",
      " \"automatic summarization\" OR \"citation analysis\" OR \"bibliometric analysis\" OR\n",
      " \"knowledge graph\" OR \"semantic web\" OR \"ontology mapping\" OR\n",
      " \"information retrieval\" OR \"text classification\" OR \"topic detection\" OR\n",
      " \"abstract summarization\" OR \"keyword extraction\" OR \"text similarity\" OR\n",
      " \"clustering algorithms\" OR \"scikit-learn\" OR \"spaCy\" OR \"gensim\" OR \"NLTK\" OR\n",
      " \"TensorFlow\" OR \"PyTorch\" OR \"Apache Spark\" OR \"Hadoop\")\n",
      "```\n",
      "\n",
      "This Boolean expression incorporates synonyms for the key concepts, technical terms related to rapid literature analysis, and contextual keywords that should help retrieve a broad yet relevant set of documents.\n"
     ]
    }
   ],
   "source": [
    "print(query_expansion_chain.invoke({\"query\":\"How to analyze a large number of papers quickly\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d618338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Answer the question based on the context provided. Stick to the context and do not add information outside it in your answers\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm=llm, prompt = qa_prompt)\n",
    "\n",
    "rag_pipeline= (\n",
    "    RunnableMap({\n",
    "        \"input\": lambda x:x[\"input\"],\n",
    "        \"context\": lambda x: retriever.invoke(query_expansion_chain.invoke({\"query\": x[\"input\"]}))\n",
    "    })\n",
    "    | document_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "779d76d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Expanded query:**\n",
      "\n",
      "\"How to rapidly analyze a large volume of scientific papers, research articles, or academic publications efficiently using automated text mining, natural language processing (NLP), machine learning, deep learning, topic modeling, clustering, bibliometric analysis, citation‑network analysis, and AI‑driven summarization for fast systematic reviews, rapid evidence synthesis, and meta‑analyses (paper triage, high‑throughput literature screening, rapid review methodology, evidence mapping, automated systematic review tools, big‑data literature analysis, computational literature review, and research synthesis techniques).\"\n",
      "Answer:\n",
      "**How to analyze a large number of scientific papers quickly**\n",
      "\n",
      "1. **Use LangChain to extract and summarize**  \n",
      "   * Run LangChain on the entire dataset to pull out key information (methods, results, citations).  \n",
      "   * Let LangChain generate concise summaries for each paper, so you can skim the main points at a glance.\n",
      "\n",
      "2. **Answer specific questions with LangChain**  \n",
      "   * Pose targeted queries (e.g., “Which papers discuss X?” or “What are the common limitations?”) and let LangChain pull the relevant passages.\n",
      "\n",
      "3. **Organize the results with CrewAI**  \n",
      "   * Feed the extracted data into CrewAI.  \n",
      "   * CrewAI can group papers into themes, create a task list, and assign team members to dive deeper into each cluster.\n",
      "\n",
      "4. **Track progress and automate follow‑ups**  \n",
      "   * CrewAI monitors task completion and automatically sends follow‑up emails or notifications to keep the project moving.\n",
      "\n",
      "5. **Generate insights and visualizations**  \n",
      "   * CrewAI produces metrics such as response times, citation trends, and overall sentiment, giving the team a quick overview of the dataset’s landscape.\n",
      "\n",
      "By combining LangChain’s extraction and summarization power with CrewAI’s task‑management, automation, and insight‑generation capabilities, researchers can rapidly process and make sense of hundreds or thousands of scientific papers.\n"
     ]
    }
   ],
   "source": [
    "# Run Query\n",
    "query = {\"input\":\"How to analyze a large number of scientific papers quickly\"}\n",
    "print(query_expansion_chain.invoke({\"query\": query}))\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(f\"Answer:\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444f1ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Expanded Query (to boost document retrieval for “Crew AI Agents”):**\n",
      "\n",
      "```\n",
      "(\n",
      "  \"Crew AI Agents\" OR\n",
      "  \"AI crew management\" OR\n",
      "  \"AI crew scheduling\" OR\n",
      "  \"AI crew optimization\" OR\n",
      "  \"AI crew automation\" OR\n",
      "  \"AI crew resource planning\" OR\n",
      "  \"AI crew coordination\" OR\n",
      "  \"AI crew assistant\" OR\n",
      "  \"AI crew system\" OR\n",
      "  \"AI‑driven crew management\" OR\n",
      "  \"AI‑based crew operations\" OR\n",
      "  \"AI crew tools\" OR\n",
      "  \"AI crew platform\" OR\n",
      "  \"AI crew simulation\" OR\n",
      "  \"AI crew integration\" OR\n",
      "  \"AI crew algorithms\" OR\n",
      "  \"AI crew agent\" OR\n",
      "  \"AI autonomous agent for crew\" OR\n",
      "  \"intelligent agent for crew\" OR\n",
      "  \"AI agent for crew management\" OR\n",
      "  \"crew AI agent system\" OR\n",
      "  \"crew AI agent architecture\" OR\n",
      "  \"crew AI agent deployment\"\n",
      ")\n",
      "AND (\n",
      "  \"aircraft crew\" OR\n",
      "  \"flight crew\" OR\n",
      "  \"pilot crew\" OR\n",
      "  \"maritime crew\" OR\n",
      "  \"ship crew\" OR\n",
      "  \"space crew\" OR\n",
      "  \"crew members\" OR\n",
      "  \"crew operations\"\n",
      ")\n",
      "AND (\n",
      "  \"human‑AI collaboration\" OR\n",
      "  \"AI‑human teamwork\" OR\n",
      "  \"human‑in‑the‑loop\" OR\n",
      "  \"AI assistance for crew\"\n",
      ")\n",
      "```\n",
      "\n",
      "**Why this helps:**\n",
      "\n",
      "- **Synonyms & Variants:** Captures different ways the same concept is phrased (e.g., “AI crew management” vs. “Crew AI Agents”).\n",
      "- **Domain‑Specific Context:** Includes aviation, maritime, and space contexts where crew AI is most relevant.\n",
      "- **Technical Terms:** Adds phrases like “intelligent agent,” “autonomous agent,” and “AI‑driven” that are common in research papers and industry docs.\n",
      "- **Human‑AI Interaction:** Incorporates collaboration terms to surface literature on mixed‑initiative systems and safety protocols.\n",
      "\n",
      "Use this expanded query in your search engine or database to retrieve a broader, more relevant set of documents.\n",
      "Answer:\n",
      "**Crew AI Agents**\n",
      "\n",
      "Agents in CrewAI are AI‑driven components that use large language models (LLMs) to decide what actions to take—such as querying a database or calling an API. They work alongside LangChain to process customer queries, generate responses, assign tasks to team members, automate follow‑up emails and notifications, and provide visual insights on metrics like response times and customer satisfaction.\n"
     ]
    }
   ],
   "source": [
    "query = {\"input\":\"Crew AI Agents\"}\n",
    "print(query_expansion_chain.invoke({\"query\": query}))\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(f\"Answer:\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
