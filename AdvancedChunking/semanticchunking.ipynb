{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e84ba19",
   "metadata": {},
   "source": [
    "# Semantic Chunking\n",
    "\n",
    "- Semantic Chunker is a document splitter that uses embedding similarity between sentences to decide chunk boundaries.\n",
    "\n",
    "- It ensures that each chunk is semantically coherent and not cut offf mid-thought like traditional character/token splitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5d3b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Chunks:\n",
      "Chunk 1: Langchain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "Chunk 2: You can create chains, agent, memory, and retrievers.\n",
      "Chunk 3: The Eiffel Tower is located in Paris.\n",
      "Chunk 4: France is a popular tourist destination.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "## Sample text\n",
    "text = \"\"\"Langchain is a framework for building applications with LLMs.\n",
    "Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains, agent, memory, and retrievers.\n",
    "The Eiffel Tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "## Step 1: Split into sentences\n",
    "sentences = [s.strip() for s in text.split('\\n') if s.strip()] # if s.strip() condition filters out any lines that would become empty after stripping\n",
    "\n",
    "## Step 2: Embed each sentence\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "## Step 3: Initialize parametes\n",
    "threshold = 0.7  # control chunk tightness\n",
    "chunks = []\n",
    "current_chunk = [sentences[0]]\n",
    "\n",
    "## Step 4: Semantic Chunking based on threshold\n",
    "\n",
    "for i in range(1, len(sentences)):\n",
    "    sim = cosine_similarity([embeddings[i]], [embeddings[i-1]])[0][0]\n",
    "    if sim >= threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "        current_chunk = [sentences[i]]\n",
    "\n",
    "# Finalize last chunk\n",
    "chunks.append(' '.join(current_chunk))\n",
    "\n",
    "## Output the chunks\n",
    "print(\"Semantic Chunks:\")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {idx+1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc9ce25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_classic.chat_models import init_chat_model\n",
    "from langchain_classic.schema.runnable import RunnablePassthrough, RunnableMap\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "246c89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Semantic Chunker with Threshold\n",
    "\n",
    "class ThresholdSemanticChunker:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', threshold=0.7):\n",
    "        self.model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def split(self, text: str):\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        embeddings = self.model.embed_documents(sentences)\n",
    "\n",
    "        chunks = []\n",
    "        current_chunk = [sentences[0]]\n",
    "\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim = cosine_similarity([embeddings[i]], [embeddings[i-1]])[0][0]\n",
    "            if sim >= self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(' '.join(current_chunk))\n",
    "                current_chunk = [sentences[i]]\n",
    "\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "        return chunks\n",
    "    \n",
    "    def split_documents(self, documents):\n",
    "        result = []\n",
    "        for doc in documents:\n",
    "            chunks = self.split(doc.page_content)\n",
    "            for chunk in chunks:\n",
    "                result.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93ef9f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='Langchain is a framework for building applications with LLMs.\\nLangchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\\nYou can create chains, agent, memory, and retrievers.\\nThe Eiffel Tower is located in Paris.\\nFrance is a popular tourist destination.\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sample text\n",
    "text = \"\"\"Langchain is a framework for building applications with LLMs.\n",
    "Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains, agent, memory, and retrievers.\n",
    "The Eiffel Tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "doc = Document(page_content=text, metadata={})\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef839c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Langchain is a framework for building applications with LLMs Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone'),\n",
       " Document(metadata={}, page_content='You can create chains, agent, memory, and retrievers'),\n",
       " Document(metadata={}, page_content='The Eiffel Tower is located in Paris'),\n",
       " Document(metadata={}, page_content='France is a popular tourist destination')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = ThresholdSemanticChunker(threshold=0.6)\n",
    "chunks = chunker.split_documents([doc])\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "565c7d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32dbd2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based on the following context:\\n\\n{context}\\n\\nQuestion: {question}\\n')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Template\n",
    "\n",
    "template = \"\"\"Answer the question based on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4075a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Langchain is a framework for building applications that use large language models (LLMs). It offers modular abstractions—such as chains, agents, memory, and retrievers—to combine LLMs with tools like OpenAI, Pinecone, and other services.\n"
     ]
    }
   ],
   "source": [
    "llm = init_chat_model(\"groq:openai/gpt-oss-20b\")\n",
    "\n",
    "### LCEL chain with retrieval\n",
    "\n",
    "rag_lcel_chain = (RunnableMap({\n",
    "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "})\n",
    "| prompt\n",
    "| llm\n",
    "| StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the RAG chain\n",
    "query={\"question\": \"What is Langchain used for?\"}\n",
    "response = rag_lcel_chain.invoke(query)\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
