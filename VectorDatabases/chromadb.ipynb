{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d16fc8f",
   "metadata": {},
   "source": [
    "## Build a RAG System with Langchain and ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91599138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c0e21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Langchain Imports\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# vector stores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Utility imports\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcfeda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It involves various algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. The key types of machine learning include supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data. Reinforcement learning involves training agents to make sequences of decisions by rewarding desired behaviors. Applications of machine learning span across various industries, including healthcare, finance, marketing, and more. Common algorithms used in machine learning include decision trees, support vector machines, neural networks, and clustering techniques. As the field continues to evolve, advancements in deep learning and neural networks are driving significant progress in areas such as computer vision, natural language processing, and autonomous systems.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and human language. It involves the development of algorithms and models that enable machines to understand, interpret, and generate human language in a way that is meaningful. NLP encompasses various tasks such as text classification, sentiment analysis, named entity recognition, machine translation, and speech recognition. Techniques used in NLP include tokenization, part-of-speech tagging, syntactic parsing, and semantic analysis. Recent advancements in NLP have been driven by deep learning models such as transformers, which have significantly improved the performance of language models like BERT and GPT. Applications of NLP are widespread, including chatbots, virtual assistants, automated customer support, and content recommendation systems. As NLP continues to advance, it plays a crucial role in enhancing human-computer interaction and enabling more natural communication with technology.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are inspired by the structure and function of the human brain, consisting of interconnected nodes (neurons) that process information. Deep learning has revolutionized various fields, including computer vision, natural language processing, and speech recognition, by enabling the development of models that can automatically learn hierarchical representations of data. Key architectures in deep learning include convolutional neural networks (CNNs) for image processing, recurrent neural networks (RNNs) for sequential data, and transformers for language modeling. Training deep learning models typically requires large datasets and significant computational resources, often utilizing GPUs for efficient processing. The success of deep learning has led to breakthroughs in applications such as autonomous vehicles, medical image analysis, and real-time language translation. As research continues, deep learning is expected to drive further innovations in artificial intelligence and its applications across various domains.\\n    ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "\n",
    "    Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It involves various algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. The key types of machine learning include supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data. Reinforcement learning involves training agents to make sequences of decisions by rewarding desired behaviors. Applications of machine learning span across various industries, including healthcare, finance, marketing, and more. Common algorithms used in machine learning include decision trees, support vector machines, neural networks, and clustering techniques. As the field continues to evolve, advancements in deep learning and neural networks are driving significant progress in areas such as computer vision, natural language processing, and autonomous systems.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "\n",
    "    Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and human language. It involves the development of algorithms and models that enable machines to understand, interpret, and generate human language in a way that is meaningful. NLP encompasses various tasks such as text classification, sentiment analysis, named entity recognition, machine translation, and speech recognition. Techniques used in NLP include tokenization, part-of-speech tagging, syntactic parsing, and semantic analysis. Recent advancements in NLP have been driven by deep learning models such as transformers, which have significantly improved the performance of language models like BERT and GPT. Applications of NLP are widespread, including chatbots, virtual assistants, automated customer support, and content recommendation systems. As NLP continues to advance, it plays a crucial role in enhancing human-computer interaction and enabling more natural communication with technology.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "\n",
    "    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are inspired by the structure and function of the human brain, consisting of interconnected nodes (neurons) that process information. Deep learning has revolutionized various fields, including computer vision, natural language processing, and speech recognition, by enabling the development of models that can automatically learn hierarchical representations of data. Key architectures in deep learning include convolutional neural networks (CNNs) for image processing, recurrent neural networks (RNNs) for sequential data, and transformers for language modeling. Training deep learning models typically requires large datasets and significant computational resources, often utilizing GPUs for efficient processing. The success of deep learning has led to breakthroughs in applications such as autonomous vehicles, medical image analysis, and real-time language translation. As research continues, deep learning is expected to drive further innovations in artificial intelligence and its applications across various domains.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ae12d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents saved to root\n"
     ]
    }
   ],
   "source": [
    "### save sample documents to files\n",
    "import tempfile\n",
    "# temp_dir= tempfile.mkdtemp()\n",
    "\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    # with open(os.path.join(temp_dir, f\"doc_{i}.txt\"), \"w\") as f:\n",
    "    #     f.write(doc)\n",
    "    with open(f\"doc_{i}.txt\", \"w\") as f:\n",
    "        f.write(doc.strip())\n",
    "\n",
    "print(f\"Sample documents saved to root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c456ea",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c21cf611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents.\n",
      "First document content:\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It involves various al\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('.', glob='doc_*.txt', loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(\"First document content:\")\n",
    "print(documents[0].page_content[:200])  # print first 200 characters of the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57946582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It involves various algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. The key types of machine learning include supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data. Reinforcement learning involves training agents to make sequences of decisions by rewarding desired behaviors. Applications of machine learning span across various industries, including healthcare, finance, marketing, and more. Common algorithms used in machine learning include decision trees, support vector machines, neural networks, and clustering techniques. As the field continues to evolve, advancements in deep learning and neural networks are driving significant progress in areas such as computer vision, natural language processing, and autonomous systems.'),\n",
       " Document(metadata={'source': 'doc_1.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and human language. It involves the development of algorithms and models that enable machines to understand, interpret, and generate human language in a way that is meaningful. NLP encompasses various tasks such as text classification, sentiment analysis, named entity recognition, machine translation, and speech recognition. Techniques used in NLP include tokenization, part-of-speech tagging, syntactic parsing, and semantic analysis. Recent advancements in NLP have been driven by deep learning models such as transformers, which have significantly improved the performance of language models like BERT and GPT. Applications of NLP are widespread, including chatbots, virtual assistants, automated customer support, and content recommendation systems. As NLP continues to advance, it plays a crucial role in enhancing human-computer interaction and enabling more natural communication with technology.'),\n",
       " Document(metadata={'source': 'doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are inspired by the structure and function of the human brain, consisting of interconnected nodes (neurons) that process information. Deep learning has revolutionized various fields, including computer vision, natural language processing, and speech recognition, by enabling the development of models that can automatically learn hierarchical representations of data. Key architectures in deep learning include convolutional neural networks (CNNs) for image processing, recurrent neural networks (RNNs) for sequential data, and transformers for language modeling. Training deep learning models typically requires large datasets and significant computational resources, often utilizing GPUs for efficient processing. The success of deep learning has led to breakthroughs in applications such as autonomous vehicles, medical image analysis, and real-time language translation. As research continues, deep learning is expected to drive further innovations in artificial intelligence and its applications across various domains.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec19d0",
   "metadata": {},
   "source": [
    "## Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33596c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It involves various algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. The key types of machine learning include supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised'),\n",
       " Document(metadata={'source': 'doc_0.txt'}, page_content='labeled data to train models, while unsupervised learning finds patterns in unlabeled data. Reinforcement learning involves training agents to make sequences of decisions by rewarding desired behaviors. Applications of machine learning span across various industries, including healthcare, finance, marketing, and more. Common algorithms used in machine learning include decision trees, support vector machines, neural networks, and clustering techniques. As the field continues to evolve,'),\n",
       " Document(metadata={'source': 'doc_0.txt'}, page_content='techniques. As the field continues to evolve, advancements in deep learning and neural networks are driving significant progress in areas such as computer vision, natural language processing, and autonomous systems.'),\n",
       " Document(metadata={'source': 'doc_1.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and human language. It involves the development of algorithms and models that enable machines to understand, interpret, and generate human language in a way that is meaningful. NLP encompasses various tasks such as text classification, sentiment analysis, named entity recognition, machine translation, and speech recognition. Techniques'),\n",
       " Document(metadata={'source': 'doc_1.txt'}, page_content='translation, and speech recognition. Techniques used in NLP include tokenization, part-of-speech tagging, syntactic parsing, and semantic analysis. Recent advancements in NLP have been driven by deep learning models such as transformers, which have significantly improved the performance of language models like BERT and GPT. Applications of NLP are widespread, including chatbots, virtual assistants, automated customer support, and content recommendation systems. As NLP continues to advance, it'),\n",
       " Document(metadata={'source': 'doc_1.txt'}, page_content='systems. As NLP continues to advance, it plays a crucial role in enhancing human-computer interaction and enabling more natural communication with technology.'),\n",
       " Document(metadata={'source': 'doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are inspired by the structure and function of the human brain, consisting of interconnected nodes (neurons) that process information. Deep learning has revolutionized various fields, including computer vision, natural language processing, and speech recognition, by enabling the development of models that'),\n",
       " Document(metadata={'source': 'doc_2.txt'}, page_content='by enabling the development of models that can automatically learn hierarchical representations of data. Key architectures in deep learning include convolutional neural networks (CNNs) for image processing, recurrent neural networks (RNNs) for sequential data, and transformers for language modeling. Training deep learning models typically requires large datasets and significant computational resources, often utilizing GPUs for efficient processing. The success of deep learning has led to'),\n",
       " Document(metadata={'source': 'doc_2.txt'}, page_content='The success of deep learning has led to breakthroughs in applications such as autonomous vehicles, medical image analysis, and real-time language translation. As research continues, deep learning is expected to drive further innovations in artificial intelligence and its applications across various domains.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\" \"] # Hierarchy of separators\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d638dc71",
   "metadata": {},
   "source": [
    "## Initialize ChromaDB Vector store and store the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a80a2c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 9 vectors.\n",
      "Vectors persisted in directory: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "## Create a ChromaDB Vector Store\n",
    "\n",
    "persist_directory = './chroma_db'\n",
    "\n",
    "## Initialize ChromaDB with HuggingFace Embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vectorstore._collection.count()} vectors.\")\n",
    "print(f\"Vectors persisted in directory: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a37e6",
   "metadata": {},
   "source": [
    "### Test Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23ba9f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It involves various algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. The key types of machine learning include supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised'),\n",
       " Document(metadata={'source': 'doc_0.txt'}, page_content='labeled data to train models, while unsupervised learning finds patterns in unlabeled data. Reinforcement learning involves training agents to make sequences of decisions by rewarding desired behaviors. Applications of machine learning span across various industries, including healthcare, finance, marketing, and more. Common algorithms used in machine learning include decision trees, support vector machines, neural networks, and clustering techniques. As the field continues to evolve,'),\n",
       " Document(metadata={'source': 'doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are inspired by the structure and function of the human brain, consisting of interconnected nodes (neurons) that process information. Deep learning has revolutionized various fields, including computer vision, natural language processing, and speech recognition, by enabling the development of models that')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are types of machine learning?\"\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "046ba891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'doc_1.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and human language. It involves the development of algorithms and models that enable machines to understand, interpret, and generate human language in a way that is meaningful. NLP encompasses various tasks such as text classification, sentiment analysis, named entity recognition, machine translation, and speech recognition. Techniques'),\n",
       " Document(metadata={'source': 'doc_1.txt'}, page_content='systems. As NLP continues to advance, it plays a crucial role in enhancing human-computer interaction and enabling more natural communication with technology.'),\n",
       " Document(metadata={'source': 'doc_1.txt'}, page_content='translation, and speech recognition. Techniques used in NLP include tokenization, part-of-speech tagging, syntactic parsing, and semantic analysis. Recent advancements in NLP have been driven by deep learning models such as transformers, which have significantly improved the performance of language models like BERT and GPT. Applications of NLP are widespread, including chatbots, virtual assistants, automated customer support, and content recommendation systems. As NLP continues to advance, it')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is NLP?\"\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "145374ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are inspired by the structure and function of the human brain, consisting of interconnected nodes (neurons) that process information. Deep learning has revolutionized various fields, including computer vision, natural language processing, and speech recognition, by enabling the development of models that'),\n",
       " Document(metadata={'source': 'doc_2.txt'}, page_content='by enabling the development of models that can automatically learn hierarchical representations of data. Key architectures in deep learning include convolutional neural networks (CNNs) for image processing, recurrent neural networks (RNNs) for sequential data, and transformers for language modeling. Training deep learning models typically requires large datasets and significant computational resources, often utilizing GPUs for efficient processing. The success of deep learning has led to'),\n",
       " Document(metadata={'source': 'doc_2.txt'}, page_content='The success of deep learning has led to breakthroughs in applications such as autonomous vehicles, medical image analysis, and real-time language translation. As research continues, deep learning is expected to drive further innovations in artificial intelligence and its applications across various domains.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is deep learning?\"\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d74b571",
   "metadata": {},
   "source": [
    "### Advanced Similarity Search with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6932184d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are inspired by the structure and function of the human brain, consisting of interconnected nodes (neurons) that process information. Deep learning has revolutionized various fields, including computer vision, natural language processing, and speech recognition, by enabling the development of models that'),\n",
       "  0.5512487888336182),\n",
       " (Document(metadata={'source': 'doc_2.txt'}, page_content='by enabling the development of models that can automatically learn hierarchical representations of data. Key architectures in deep learning include convolutional neural networks (CNNs) for image processing, recurrent neural networks (RNNs) for sequential data, and transformers for language modeling. Training deep learning models typically requires large datasets and significant computational resources, often utilizing GPUs for efficient processing. The success of deep learning has led to'),\n",
       "  0.6596519947052002),\n",
       " (Document(metadata={'source': 'doc_2.txt'}, page_content='The success of deep learning has led to breakthroughs in applications such as autonomous vehicles, medical image analysis, and real-time language translation. As research continues, deep learning is expected to drive further innovations in artificial intelligence and its applications across various domains.'),\n",
       "  0.8478018045425415)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_scores= vectorstore.similarity_search_with_score(query, k=3)\n",
    "result_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d135fb",
   "metadata": {},
   "source": [
    "### Understanding Similarity Scores\n",
    "\n",
    "The similarity score represents how closely related a document chunk is to your query, The scoring depends on the distance metric used:\n",
    "\n",
    "ChromaDB by default uses L2 distance (Euclidean distance)\n",
    "- Lower scores =  MORE similar (closer in vector space)\n",
    "- Score of 0 =  identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "\n",
    "- Higher scores =  MORE similar\n",
    "- Range: -1 to 1 (1 being identical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d180556",
   "metadata": {},
   "source": [
    "## Initialize LLM, RAG Chain, Prompt Tempate, Query the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d144dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"mistral:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e41b84cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Large Language Models (LLMs) are a type of artificial intelligence model designed to process and generate human-like text. They are trained on vast amounts of internet text, learning patterns in the language that allow them to understand context, answer questions, write essays, translate languages, summarize information, and even carry on conversations.\\n\\nThe size of these models refers to the number of parameters they have â€“ essentially the number of adjustable components in the model's architecture. Larger models generally perform better but require more computational resources and time to train. Examples of large language models include Google's BERT, Microsoft's Turing NLG, and OpenAI's GPT-3. They are increasingly being used in various applications, such as chatbots, virtual assistants, content generation, and language translation services.\", additional_kwargs={}, response_metadata={'model': 'mistral:latest', 'created_at': '2025-10-26T10:25:18.583939Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4247285700, 'load_duration': 28613600, 'prompt_eval_count': 11, 'prompt_eval_duration': 839013300, 'eval_count': 172, 'eval_duration': 3311445600, 'model_name': 'mistral:latest', 'model_provider': 'ollama'}, id='lc_run--2414e7fa-74b5-4ff4-8423-2a2107832124-0', usage_metadata={'input_tokens': 11, 'output_tokens': 172, 'total_tokens': 183})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response =  llm.invoke(\"What is Large Language Models?\")\n",
    "\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea87a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='mistral:latest')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative waqy to initialize chat models\n",
    "\n",
    "from langchain.chat_models.base import init_chat_model\n",
    "\n",
    "chat_model = init_chat_model(\"ollama:mistral:latest\")\n",
    "#llm = init_chat_model(\"groq:\")\n",
    "\n",
    "chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "413330a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Reinforcement Learning (RL) is a type of machine learning that involves training an agent to make decisions by interacting with its environment. The goal is for the agent to learn a policy, which is a strategy or rule set that maps states of the environment to actions that maximize some notion of cumulative reward.\\n\\nHere's a simplified breakdown of the concept:\\n\\n1. **Agent**: In reinforcement learning, an agent interacts with its environment by performing actions and receiving rewards or punishments. The agent's goal is to learn how to take actions that maximize some notion of cumulative reward (or minimize negative reward).\\n\\n2. **State**: Each state represents a situation in the environment that the agent finds itself in. For example, consider an autonomous car driving on a highway. Each state could represent a specific configuration of the car's sensors data (e.g., speed, distance to other cars, traffic signs, etc.).\\n\\n3. **Action**: The agent chooses an action at each time step based on its current state and previous learning. The agent's goal is to learn which actions lead to desirable states with high rewards.\\n\\n4. **Reward**: The environment provides the agent with a reward signal after each action, indicating whether the chosen action was good or bad. Rewards can be positive (e.g., +1 point) or negative (e.g., -1 point). In some cases, there may also be no immediate reward, but the goal is to maximize the total cumulative reward over time.\\n\\n5. **Policy**: A policy represents a strategy that the agent uses to decide which action to take in each state. The policy can be deterministic (always choosing the same action for a given state) or stochastic (choosing actions based on probabilities).\\n\\n6. **Value Function**: The value function estimates the expected cumulative reward an agent will receive when starting from a specific state and following its current policy. It helps the agent decide whether it should take a certain action in a particular state by evaluating the potential rewards and risks.\\n\\n7. **Exploration vs Exploitation**: During learning, the agent faces a trade-off between exploring new states (actions) to gather more information and exploiting its current knowledge to achieve higher immediate rewards. Finding an optimal balance is crucial for efficient reinforcement learning.\\n\\n8. **Training**: The agent learns by iteratively interacting with its environment, trying different actions, receiving rewards, updating its policy based on the obtained knowledge, and repeating the process until it achieves a desired level of performance or convergence to an optimal policy.\\n\\nReinforcement learning has applications in various fields such as game playing (e.g., AlphaGo), robotics (e.g., grasping objects), navigation (e.g., self-driving cars), and even finance (e.g., trading strategies).\", additional_kwargs={}, response_metadata={'model': 'mistral:latest', 'created_at': '2025-10-26T10:36:53.9587587Z', 'done': True, 'done_reason': 'stop', 'total_duration': 17451470200, 'load_duration': 3844474500, 'prompt_eval_count': 13, 'prompt_eval_duration': 1224320600, 'eval_count': 619, 'eval_duration': 12103516200, 'model_name': 'mistral:latest', 'model_provider': 'ollama'}, id='lc_run--6b887db8-5ed3-4c57-b3c6-f0a75c7f31ea-0', usage_metadata={'input_tokens': 13, 'output_tokens': 619, 'total_tokens': 632})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"Explain the concept of reinforcement learning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c6a24",
   "metadata": {},
   "source": [
    "## Modern RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bc8ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains.combine_documents.stuff import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04aa403a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000018060E3B090>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert vectorstore to a retriever\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0150cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Prompt Template\n",
    "system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the context provided to answer the question as accurately as possible.\n",
    "If the context does not contain the answer, respond with 'I don't know'.\n",
    "Use three sentences maximum to answer the question and keep it concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65f34477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the context provided to answer the question as accurately as possible.\\nIf the context does not contain the answer, respond with 'I don't know'.\\nUse three sentences maximum to answer the question and keep it concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f21887a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the context provided to answer the question as accurately as possible.\\nIf the context does not contain the answer, respond with 'I don't know'.\\nUse three sentences maximum to answer the question and keep it concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOllama(model='mistral:latest')\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create Documents Chain\n",
    "documents_chain = create_stuff_documents_chain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "documents_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de171a51",
   "metadata": {},
   "source": [
    "This chain:\n",
    "\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into prompt's {context} placeholder.\n",
    "- Sends the complete prompt to the LLM.\n",
    "- Returns the LLM's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fad789f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000018060E3B090>, search_kwargs={'k': 3}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the context provided to answer the question as accurately as possible.\\nIf the context does not contain the answer, respond with 'I don't know'.\\nUse three sentences maximum to answer the question and keep it concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOllama(model='mistral:latest')\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create the Final RAG Chain\n",
    "rag_chain = create_retrieval_chain(retriever,documents_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f31b2",
   "metadata": {},
   "source": [
    "Using this create_retrieval_chain we are able to another retreval layer to our stuff document chain which uses the retriever to fetch relavant documents from our vectorstore and sends it to the stuff chain which sends it to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5fd858c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Explain the different types of machine learning.',\n",
       " 'context': [Document(metadata={'source': 'doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It involves various algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. The key types of machine learning include supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised'),\n",
       "  Document(metadata={'source': 'doc_0.txt'}, page_content='labeled data to train models, while unsupervised learning finds patterns in unlabeled data. Reinforcement learning involves training agents to make sequences of decisions by rewarding desired behaviors. Applications of machine learning span across various industries, including healthcare, finance, marketing, and more. Common algorithms used in machine learning include decision trees, support vector machines, neural networks, and clustering techniques. As the field continues to evolve,'),\n",
       "  Document(metadata={'source': 'doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are inspired by the structure and function of the human brain, consisting of interconnected nodes (neurons) that process information. Deep learning has revolutionized various fields, including computer vision, natural language processing, and speech recognition, by enabling the development of models that')],\n",
       " 'answer': ' The three main types of Machine Learning are Supervised Learning, Unsupervised Learning, and Reinforcement Learning. In Supervised Learning, labeled data is used to train models, while in Unsupervised Learning, patterns are found in unlabeled data. Reinforcement Learning involves training agents to make sequences of decisions by rewarding desired behaviors. Deep Learning, a subset of Machine Learning, uses neural networks with multiple layers to model complex patterns in data and has been instrumental in fields like computer vision, natural language processing, and speech recognition.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Explain the different types of machine learning.\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f51ef782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The three main types of Machine Learning are Supervised Learning, Unsupervised Learning, and Reinforcement Learning. In Supervised Learning, labeled data is used to train models, while in Unsupervised Learning, patterns are found in unlabeled data. Reinforcement Learning involves training agents to make sequences of decisions by rewarding desired behaviors. Deep Learning, a subset of Machine Learning, uses neural networks with multiple layers to model complex patterns in data and has been instrumental in fields like computer vision, natural language processing, and speech recognition.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c763ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are three types of machine learning?\n",
      "--------------------------------------------------\n",
      "Answer:  The three main types of machine learning are:\n",
      "1. Supervised Learning: It utilizes labeled data to train models for specific tasks.\n",
      "2. Unsupervised Learning: It finds patterns in unlabeled data without explicit instructions.\n",
      "3. Reinforcement Learning: It trains agents to make sequences of decisions by rewarding desired behaviors.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      " ----- Source 1 -----\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It involves various al...\n",
      "\n",
      " ----- Source 2 -----\n",
      "labeled data to train models, while unsupervised learning finds patterns in unlabeled data. Reinforcement learning involves training agents to make sequences of decisions by rewarding desired behavior...\n",
      "\n",
      " ----- Source 3 -----\n",
      "techniques. As the field continues to evolve, advancements in deep learning and neural networks are driving significant progress in areas such as computer vision, natural language processing, and auto...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What is Deep Learning and how does it relate to Neural Networks?\n",
      "--------------------------------------------------\n",
      "Answer:  Deep Learning is a subset of machine learning that utilizes neural networks with multiple layers to model complex patterns in data. These neural networks are inspired by the structure of the human brain, consisting of interconnected nodes (neurons) that process information. In this context, deep learning allows for the automatic learning of hierarchical representations of data, which has revolutionized fields like computer vision, natural language processing, and speech recognition.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      " ----- Source 1 -----\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are i...\n",
      "\n",
      " ----- Source 2 -----\n",
      "by enabling the development of models that can automatically learn hierarchical representations of data. Key architectures in deep learning include convolutional neural networks (CNNs) for image proce...\n",
      "\n",
      " ----- Source 3 -----\n",
      "The success of deep learning has led to breakthroughs in applications such as autonomous vehicles, medical image analysis, and real-time language translation. As research continues, deep learning is e...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What are CNNs used for?\n",
      "--------------------------------------------------\n",
      "Answer:  Convolutional Neural Networks (CNNs) are primarily used for image processing tasks. They excel at analyzing visual data by automatically identifying and learning hierarchical features within the images such as edges, shapes, and objects. Common applications of CNNs include object recognition, facial recognition, image classification, and medical image analysis.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      " ----- Source 1 -----\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning that focuses on using neural networks with multiple layers to model complex patterns in data. Neural networks are i...\n",
      "\n",
      " ----- Source 2 -----\n",
      "by enabling the development of models that can automatically learn hierarchical representations of data. Key architectures in deep learning include convolutional neural networks (CNNs) for image proce...\n",
      "\n",
      " ----- Source 3 -----\n",
      "techniques. As the field continues to evolve, advancements in deep learning and neural networks are driving significant progress in areas such as computer vision, natural language processing, and auto...\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to query the modern RAG system\n",
    "\n",
    "def query_rag_modern(question: str) -> str:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    # Using create_retrieval_chain approach\n",
    "    result = rag_chain.invoke({\"input\": question})\n",
    "\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(\"\\nRetrieved Context:\")\n",
    "    for i, doc in enumerate(result['context']):\n",
    "        print(f\"\\n ----- Source {i+1} -----\")\n",
    "        print(doc.page_content[:200]+\"...\")\n",
    "\n",
    "    return result['answer']\n",
    "\n",
    "test_questions = [\n",
    "    \"What are three types of machine learning?\",\n",
    "    \"What is Deep Learning and how does it relate to Neural Networks?\",\n",
    "    \"What are CNNs used for?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    query_rag_modern(question)\n",
    "    print(\"\\n\"+\"=\"*80+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3308c5",
   "metadata": {},
   "source": [
    "# Creating Rag Chain Alternative - Using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f65603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50376e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the context provided to answer the question as accurately as possible.\\nIf the context does not contain the answer, respond with 'I don't know'.\\nUse three sentences maximum to answer the question and keep it concise.\\n\\nContext: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a custom Prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Use the context provided to answer the question as accurately as possible.\n",
    "If the context does not contain the answer, respond with 'I don't know'.\n",
    "Use three sentences maximum to answer the question and keep it concise.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "custom_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60d3f322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000018060E3B090>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8ef6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format the output documents for the prompt\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08b63b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000018060E3B090>, search_kwargs={'k': 3})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the context provided to answer the question as accurately as possible.\\nIf the context does not contain the answer, respond with 'I don't know'.\\nUse three sentences maximum to answer the question and keep it concise.\\n\\nContext: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])\n",
       "| ChatOllama(model='mistral:latest')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build the RAG Chain using LCEL\n",
    "\n",
    "rag_chain_lcel = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | custom_prompt\n",
    "    | chat_model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "976937cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Machine Learning consists of three main types:\\n\\n1. Supervised Learning: Uses labeled data to train models, such as classification and regression tasks.\\n2. Unsupervised Learning: Finds patterns in unlabeled data, like clustering and anomaly detection.\\n3. Reinforcement Learning: Trains agents through trial-and-error by rewarding desired behaviors, typically used for sequential decision making problems.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain_lcel.invoke(\"Explain the different types of machine learning.\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4835bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are three types of machine learning?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     18\u001b[39m test_questions = [\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWhat are three types of machine learning?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWhat is Deep Learning and how does it relate to Neural Networks?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWhat are CNNs used for?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m ]\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m test_questions:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43mquery_rag_lcel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m+\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m+\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mquery_rag_lcel\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Using create_retrieval_chain approach\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m result = \u001b[43mrag_chain_lcel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRetrieved Context:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3091\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3089\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3090\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3091\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3092\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3093\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3811\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3806\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3807\u001b[39m         futures = [\n\u001b[32m   3808\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3809\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3810\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3811\u001b[39m         output = \u001b[43m{\u001b[49m\n\u001b[32m   3812\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3814\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m   3815\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3816\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3812\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   3806\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3807\u001b[39m         futures = [\n\u001b[32m   3808\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3809\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3810\u001b[39m         ]\n\u001b[32m   3811\u001b[39m         output = {\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m             key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   3814\u001b[39m         }\n\u001b[32m   3815\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3816\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3795\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input_, config, key)\u001b[39m\n\u001b[32m   3789\u001b[39m child_config = patch_config(\n\u001b[32m   3790\u001b[39m     config,\n\u001b[32m   3791\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3792\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3793\u001b[39m )\n\u001b[32m   3794\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3795\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m context.run(\n\u001b[32m   3796\u001b[39m         step.invoke,\n\u001b[32m   3797\u001b[39m         input_,\n\u001b[32m   3798\u001b[39m         child_config,\n\u001b[32m   3799\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3091\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3089\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3090\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3091\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3092\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3093\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:212\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m kwargs_ = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **kwargs_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1032\u001b[39m, in \u001b[36mVectorStoreRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1030\u001b[39m kwargs_ = \u001b[38;5;28mself\u001b[39m.search_kwargs | kwargs\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1032\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity_score_threshold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1034\u001b[39m     docs_and_similarities = (\n\u001b[32m   1035\u001b[39m         \u001b[38;5;28mself\u001b[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001b[32m   1036\u001b[39m             query, **kwargs_\n\u001b[32m   1037\u001b[39m         )\n\u001b[32m   1038\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:350\u001b[39m, in \u001b[36mChroma.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, **kwargs)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    334\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    335\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    338\u001b[39m     **kwargs: Any,\n\u001b[32m    339\u001b[39m ) -> List[Document]:\n\u001b[32m    340\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[32m    341\u001b[39m \n\u001b[32m    342\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m \u001b[33;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[32m    349\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:439\u001b[39m, in \u001b[36mChroma.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, where_document, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.__query_collection(\n\u001b[32m    432\u001b[39m         query_texts=[query],\n\u001b[32m    433\u001b[39m         n_results=k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    436\u001b[39m         **kwargs,\n\u001b[32m    437\u001b[39m     )\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     query_embedding = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.__query_collection(\n\u001b[32m    441\u001b[39m         query_embeddings=[query_embedding],\n\u001b[32m    442\u001b[39m         n_results=k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m         **kwargs,\n\u001b[32m    446\u001b[39m     )\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:172\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    159\u001b[39m \n\u001b[32m    160\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    165\u001b[39m \n\u001b[32m    166\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    167\u001b[39m embed_kwargs = (\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.query_encode_kwargs\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.query_encode_kwargs) > \u001b[32m0\u001b[39m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encode_kwargs\n\u001b[32m    171\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_kwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:124\u001b[39m, in \u001b[36mHuggingFaceEmbeddings._embed\u001b[39m\u001b[34m(self, texts, encode_kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Embed a text using the HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m    112\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m texts = \u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.multi_process:\n\u001b[32m    126\u001b[39m     pool = \u001b[38;5;28mself\u001b[39m._client.start_multi_process_pool()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAG\\RAG-Langchain\\.venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:124\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Embed a text using the HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m    112\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m texts = [\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.multi_process:\n\u001b[32m    126\u001b[39m     pool = \u001b[38;5;28mself\u001b[39m._client.start_multi_process_pool()\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "# Query using the LCEL RAG Chain\n",
    "\n",
    "def query_rag_lcel(question: str) -> str:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    # Using create_retrieval_chain approach\n",
    "    result = rag_chain_lcel.invoke({\"input\": question})\n",
    "\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(\"\\nRetrieved Context:\")\n",
    "    for i, doc in enumerate(result['context']):\n",
    "        print(f\"\\n ----- Source {i+1} -----\")\n",
    "        print(doc.page_content[:200]+\"...\")\n",
    "\n",
    "    return result['answer']\n",
    "\n",
    "test_questions = [\n",
    "    \"What are three types of machine learning?\",\n",
    "    \"What is Deep Learning and how does it relate to Neural Networks?\",\n",
    "    \"What are CNNs used for?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    query_rag_lcel(question)\n",
    "    print(\"\\n\"+\"=\"*80+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
