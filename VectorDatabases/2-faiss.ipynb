{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a7036e",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and FAISS \n",
    "Introduction to RAG (Retrieval-Augmented Generation)\n",
    "RAG combines the power of retrieval systems with generative AI models. Instead of relying solely on the model's training data, RAG:\n",
    "\n",
    "1. Retrieves relevant documents from a knowledge base\n",
    "2. Uses these documents as context for the LLM\n",
    "3. Generates responses based on both the retrieved context and the model's knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937ab9f",
   "metadata": {},
   "source": [
    "### FAISS \n",
    "https://github.com/facebookresearch/faiss\n",
    "\n",
    "FAISS is a library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "Key advantages:\n",
    "1. Extremely fast similarity search\n",
    "2. Memory efficient\n",
    "3. Supports GPU acceleration\n",
    "4. Can handle millions of vectors\n",
    "\n",
    "How it works:\n",
    "- Indexes vectors for fast nearest neighbor search\n",
    "- Returns most similar vectors based on distance metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0af024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain core imports\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import (\n",
    "    RunnablePassthrough, \n",
    " \n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# LangChain specific imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4adfdc",
   "metadata": {},
   "source": [
    "### Data Ingestion And Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511190a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}, page_content='\\n        Artificial Intelligence (AI) is the simulation of human intelligence in machines.\\n        These systems are designed to think like humans and mimic their actions.\\n        AI can be categorized into narrow AI and general AI.\\n        '), Document(metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='\\n        Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.\\n        '), Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'DL'}, page_content='\\n        Deep Learning is a subset of machine learning based on artificial neural networks.\\n        It uses multiple layers to progressively extract higher-level features from raw input.\\n        Deep learning has revolutionized computer vision, NLP, and speech recognition.\\n        '), Document(metadata={'source': 'NLP Overview', 'page': 1, 'topic': 'NLP'}, page_content='\\n        Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\\n        It combines computational linguistics with machine learning and deep learning models.\\n        Applications include chatbots, translation, sentiment analysis, and text summarization.\\n        ')]\n"
     ]
    }
   ],
   "source": [
    "sample_documents = [\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
    "        These systems are designed to think like humans and mimic their actions.\n",
    "        AI can be categorized into narrow AI and general AI.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"AI Introduction\", \"page\": 1, \"topic\": \"AI\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Machine Learning is a subset of AI that enables systems to learn from data.\n",
    "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
    "        Common types include supervised, unsupervised, and reinforcement learning.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"ML Basics\", \"page\": 1, \"topic\": \"ML\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Deep Learning is a subset of machine learning based on artificial neural networks.\n",
    "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
    "        Deep learning has revolutionized computer vision, NLP, and speech recognition.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"Deep Learning\", \"page\": 1, \"topic\": \"DL\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
    "        It combines computational linguistics with machine learning and deep learning models.\n",
    "        Applications include chatbots, translation, sentiment analysis, and text summarization.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"NLP Overview\", \"page\": 1, \"topic\": \"NLP\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(sample_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028d3f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
      "        These systems are designed to think like humans and mimic their actions.\n",
      "        AI can be categorized into narrow AI and general AI.' metadata={'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}\n",
      "page_content='Machine Learning is a subset of AI that enables systems to learn from data.\n",
      "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
      "        Common types include supervised, unsupervised, and reinforcement learning.' metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}\n"
     ]
    }
   ],
   "source": [
    "## text splitting\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\" \"]\n",
    ")\n",
    "\n",
    "## split the documents into chunks\n",
    "chunks = text_splitter.split_documents(sample_documents)\n",
    "print(chunks[0])\n",
    "print(chunks[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed228b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 chunks from 4 documents\n",
      "\n",
      "Example chunk:\n",
      "Content: Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
      "        These systems are designed to think like humans and mimic their actions.\n",
      "        AI can be categorized into narrow AI and general AI.\n",
      "Metadata: {'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(sample_documents)} documents\")\n",
    "print(\"\\nExample chunk:\")\n",
    "print(f\"Content: {chunks[0].page_content}\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1051ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the embedding models\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab0c2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.029035616666078568,\n",
       " 0.007559687364846468,\n",
       " 0.040764857083559036,\n",
       " 0.030535513535141945,\n",
       " 0.0517570935189724,\n",
       " -0.017347518354654312,\n",
       " -0.030941840261220932,\n",
       " -0.0655628889799118,\n",
       " -0.033060770481824875,\n",
       " -0.009561236947774887,\n",
       " -0.09131382405757904,\n",
       " 0.047383639961481094,\n",
       " 0.027739526703953743,\n",
       " -0.06366028636693954,\n",
       " -0.0650474801659584,\n",
       " 0.042002659291028976,\n",
       " -0.04021904617547989,\n",
       " 0.02800505980849266,\n",
       " -0.02804984711110592,\n",
       " -0.05376287177205086,\n",
       " -0.005428324919193983,\n",
       " 0.006084769498556852,\n",
       " -0.07086581736803055,\n",
       " 0.025930063799023628,\n",
       " 0.010079454630613327,\n",
       " 0.026293449103832245,\n",
       " 0.03857453539967537,\n",
       " 0.02275240048766136,\n",
       " -0.016700439155101776,\n",
       " 0.009418017230927944,\n",
       " 0.01637606881558895,\n",
       " -0.05924324691295624,\n",
       " -0.016352377831935883,\n",
       " 0.0457991287112236,\n",
       " -0.0612017959356308,\n",
       " 0.0611710250377655,\n",
       " -0.013366789557039738,\n",
       " -0.00031110935378819704,\n",
       " 0.03935341536998749,\n",
       " -0.04183918610215187,\n",
       " -0.03927674889564514,\n",
       " -0.10107356309890747,\n",
       " -0.006085154600441456,\n",
       " -0.011100586503744125,\n",
       " 0.12034152448177338,\n",
       " 0.10397816449403763,\n",
       " -0.05519599840044975,\n",
       " -0.11298873275518417,\n",
       " -0.032693810760974884,\n",
       " 0.014702778309583664,\n",
       " -0.09101350605487823,\n",
       " -0.038357265293598175,\n",
       " 0.0027517136186361313,\n",
       " -0.008734752424061298,\n",
       " -0.05779314041137695,\n",
       " 0.03315157815814018,\n",
       " 0.05066530033946037,\n",
       " -0.009161517024040222,\n",
       " 0.001982788322493434,\n",
       " -0.011107951402664185,\n",
       " 0.015205711126327515,\n",
       " -0.1520676612854004,\n",
       " -0.02410752698779106,\n",
       " 0.03700374439358711,\n",
       " 0.06354305148124695,\n",
       " -0.02727144956588745,\n",
       " -0.037051696330308914,\n",
       " 0.014332626014947891,\n",
       " 0.007579023018479347,\n",
       " -0.09305106848478317,\n",
       " -0.010146299377083778,\n",
       " 0.04867212474346161,\n",
       " 0.010806997306644917,\n",
       " 0.07799927890300751,\n",
       " 0.039215266704559326,\n",
       " 0.008822125382721424,\n",
       " 0.0032743935007601976,\n",
       " -0.0266698207706213,\n",
       " 0.09167906641960144,\n",
       " 0.06515677273273468,\n",
       " -0.012353208847343922,\n",
       " 0.018279409036040306,\n",
       " -0.0440206341445446,\n",
       " 0.08364029973745346,\n",
       " 0.06395307928323746,\n",
       " -0.055060334503650665,\n",
       " -0.05808801203966141,\n",
       " -0.0018746922723948956,\n",
       " -0.047405730932950974,\n",
       " -0.027536258101463318,\n",
       " -0.028804738074541092,\n",
       " -0.027462659403681755,\n",
       " -0.021264029666781425,\n",
       " -0.018902095034718513,\n",
       " -0.061730220913887024,\n",
       " 0.027876460924744606,\n",
       " -0.02547568269073963,\n",
       " -0.1032743826508522,\n",
       " 0.006333625875413418,\n",
       " 0.07414139807224274,\n",
       " -0.05245543643832207,\n",
       " 0.08629942685365677,\n",
       " 0.012340130284428596,\n",
       " -0.02364429458975792,\n",
       " 0.06663606315851212,\n",
       " -0.013113784603774548,\n",
       " 0.014714319258928299,\n",
       " -0.02359590120613575,\n",
       " 0.09515438228845596,\n",
       " -0.1160663589835167,\n",
       " -0.06480208784341812,\n",
       " 0.028634214773774147,\n",
       " -0.031554922461509705,\n",
       " -0.04173007979989052,\n",
       " -0.03608330711722374,\n",
       " -0.006182917859405279,\n",
       " -0.03813053295016289,\n",
       " 0.0043206484988331795,\n",
       " -0.03699595108628273,\n",
       " 0.06302621960639954,\n",
       " -0.06653683632612228,\n",
       " 6.598339678021148e-05,\n",
       " 0.004346258006989956,\n",
       " 0.025370946153998375,\n",
       " 0.02638273313641548,\n",
       " -0.0990356057882309,\n",
       " -0.07831862568855286,\n",
       " -6.0102104129162134e-33,\n",
       " 0.024687649682164192,\n",
       " -0.10524410754442215,\n",
       " 0.0009759574895724654,\n",
       " -0.02323167771100998,\n",
       " 0.04899432510137558,\n",
       " -0.10262829810380936,\n",
       " -0.035019584000110626,\n",
       " -0.0634978786110878,\n",
       " 0.0298029612749815,\n",
       " 0.0378592349588871,\n",
       " -0.029759755358099937,\n",
       " 0.007283463608473539,\n",
       " 0.03714795783162117,\n",
       " 0.06798268854618073,\n",
       " 0.06864475458860397,\n",
       " 0.026472274214029312,\n",
       " -0.007139055989682674,\n",
       " 0.04937400296330452,\n",
       " 0.01627492904663086,\n",
       " -0.04618830978870392,\n",
       " 0.03898201137781143,\n",
       " 0.008404077030718327,\n",
       " 0.0299586933106184,\n",
       " 0.021006712689995766,\n",
       " -0.03257214277982712,\n",
       " 0.06217188015580177,\n",
       " 0.029418883845210075,\n",
       " 0.07485553622245789,\n",
       " 0.043728310614824295,\n",
       " 0.033515915274620056,\n",
       " 0.01361318863928318,\n",
       " 0.013984964229166508,\n",
       " -0.0536143034696579,\n",
       " 0.003676455933600664,\n",
       " 0.04363549128174782,\n",
       " -0.01090785302221775,\n",
       " -0.0037536199670284986,\n",
       " -0.004634924698621035,\n",
       " 0.04214831441640854,\n",
       " 0.028949419036507607,\n",
       " 0.008460812270641327,\n",
       " -0.045049555599689484,\n",
       " 0.0733589380979538,\n",
       " -0.07362175732851028,\n",
       " -0.07764670997858047,\n",
       " 0.05312056466937065,\n",
       " 0.015657272189855576,\n",
       " -0.1068151518702507,\n",
       " -0.07902579009532928,\n",
       " -0.04125155508518219,\n",
       " -0.028915664181113243,\n",
       " -0.06834134459495544,\n",
       " -0.03997888043522835,\n",
       " 0.006200808100402355,\n",
       " 0.022057246416807175,\n",
       " 0.10797025263309479,\n",
       " -0.0024694129824638367,\n",
       " -0.003463766071945429,\n",
       " -0.05418188124895096,\n",
       " -0.005846310872584581,\n",
       " 0.05413011088967323,\n",
       " 0.05295936018228531,\n",
       " 0.020870326086878777,\n",
       " 0.0789758488535881,\n",
       " -0.010170377790927887,\n",
       " 0.015605548396706581,\n",
       " 0.08540284633636475,\n",
       " 0.041051365435123444,\n",
       " 0.08442148566246033,\n",
       " -0.009051015600562096,\n",
       " 0.04345434159040451,\n",
       " 0.007145541720092297,\n",
       " 0.025493405759334564,\n",
       " -0.037962283939123154,\n",
       " 0.06106003001332283,\n",
       " -0.011417022906243801,\n",
       " 0.052369412034749985,\n",
       " 0.04044767841696739,\n",
       " -0.019636599346995354,\n",
       " 0.05107370764017105,\n",
       " -0.022881802171468735,\n",
       " -0.03634713590145111,\n",
       " -0.003598575247451663,\n",
       " -0.076582171022892,\n",
       " -0.013934822753071785,\n",
       " 0.0564463771879673,\n",
       " -0.027651488780975342,\n",
       " -0.03730526193976402,\n",
       " -0.03187881037592888,\n",
       " 0.015561716631054878,\n",
       " -0.12173198163509369,\n",
       " 0.007317938841879368,\n",
       " 0.011212221346795559,\n",
       " 0.01980379782617092,\n",
       " -0.06352609395980835,\n",
       " 2.327825585461622e-33,\n",
       " -0.06423313170671463,\n",
       " 0.009110329672694206,\n",
       " -0.013949165120720863,\n",
       " 0.09450729191303253,\n",
       " 0.030099667608737946,\n",
       " 0.01408088207244873,\n",
       " -0.078463613986969,\n",
       " 0.032595712691545486,\n",
       " -0.08949311822652817,\n",
       " 0.06275834888219833,\n",
       " 0.016260851174592972,\n",
       " -0.021571652963757515,\n",
       " 0.08164015412330627,\n",
       " 0.03085721656680107,\n",
       " -0.0041921925731003284,\n",
       " 0.059583235532045364,\n",
       " -0.07337910681962967,\n",
       " -0.011431370861828327,\n",
       " -0.03510401397943497,\n",
       " 0.04826776683330536,\n",
       " -0.017872994765639305,\n",
       " 0.06025490537285805,\n",
       " 0.022646727040410042,\n",
       " -0.016905656084418297,\n",
       " 0.04184361919760704,\n",
       " -0.017204128205776215,\n",
       " -0.03755875676870346,\n",
       " 0.025142323225736618,\n",
       " -0.02586958184838295,\n",
       " 0.02874044142663479,\n",
       " 0.002235973021015525,\n",
       " 0.025622976943850517,\n",
       " -0.03696339577436447,\n",
       " 0.006591036915779114,\n",
       " 0.056292664259672165,\n",
       " 0.016468992456793785,\n",
       " 0.028691353276371956,\n",
       " -0.05175889655947685,\n",
       " 0.038454730063676834,\n",
       " 0.09314852207899094,\n",
       " -0.006300165317952633,\n",
       " 0.018203161656856537,\n",
       " -0.07134728878736496,\n",
       " -0.08328653872013092,\n",
       " -0.0335078239440918,\n",
       " -0.013967207632958889,\n",
       " -0.01000146009027958,\n",
       " -0.018659938126802444,\n",
       " 0.06312134861946106,\n",
       " -0.08709114789962769,\n",
       " 0.021946948021650314,\n",
       " 0.09118974208831787,\n",
       " 0.02197187952697277,\n",
       " -0.05642060935497284,\n",
       " -0.023548120632767677,\n",
       " 0.0478273406624794,\n",
       " -0.042867790907621384,\n",
       " 0.015484861098229885,\n",
       " 0.009332413785159588,\n",
       " 0.10468807071447372,\n",
       " -0.06996075063943863,\n",
       " -0.040213074535131454,\n",
       " 0.04386870190501213,\n",
       " -0.025810975581407547,\n",
       " 0.004301638808101416,\n",
       " 0.0712687224149704,\n",
       " 0.010412922129034996,\n",
       " 0.06600608676671982,\n",
       " -0.02565276063978672,\n",
       " 0.005441865883767605,\n",
       " 0.03430505469441414,\n",
       " 0.08808629959821701,\n",
       " -0.004543820861726999,\n",
       " 0.0909951776266098,\n",
       " -0.04836506396532059,\n",
       " -0.08146053552627563,\n",
       " -0.020732097327709198,\n",
       " -0.05615421012043953,\n",
       " -0.05486655980348587,\n",
       " -0.01037977822124958,\n",
       " 0.03315400704741478,\n",
       " -0.11480741947889328,\n",
       " 0.01881619356572628,\n",
       " 0.06738897413015366,\n",
       " -0.002072036499157548,\n",
       " -0.04970713332295418,\n",
       " 0.006136351265013218,\n",
       " 0.021939922124147415,\n",
       " -0.04654264822602272,\n",
       " -0.07037465274333954,\n",
       " -0.04876381903886795,\n",
       " 0.03741265833377838,\n",
       " -0.06766540557146072,\n",
       " 0.07526881992816925,\n",
       " -0.10176168382167816,\n",
       " -1.3521182395948017e-08,\n",
       " -0.007577819284051657,\n",
       " -0.023337915539741516,\n",
       " 0.09829696267843246,\n",
       " -0.08803718537092209,\n",
       " 0.08125018328428268,\n",
       " 0.05348080396652222,\n",
       " -0.07778520882129669,\n",
       " 0.09395746886730194,\n",
       " -0.0469672828912735,\n",
       " -0.04920145869255066,\n",
       " 0.03322502225637436,\n",
       " 0.04946211352944374,\n",
       " -0.03181486949324608,\n",
       " 0.02286977507174015,\n",
       " -0.04232319816946983,\n",
       " 0.009407575242221355,\n",
       " 0.02744465321302414,\n",
       " 0.026070328429341316,\n",
       " 0.009801078587770462,\n",
       " 0.08153563737869263,\n",
       " 0.11052553355693817,\n",
       " -0.030864698812365532,\n",
       " 0.033376213163137436,\n",
       " -0.05804486572742462,\n",
       " 0.1101701483130455,\n",
       " -0.13507062196731567,\n",
       " -0.004004014190286398,\n",
       " 0.05443382263183594,\n",
       " -0.006387466099113226,\n",
       " 0.004197020549327135,\n",
       " -0.07071342319250107,\n",
       " 0.08257732540369034,\n",
       " 0.02240721508860588,\n",
       " -0.01586313731968403,\n",
       " 0.024661671370267868,\n",
       " 0.06775177270174026,\n",
       " 0.0565558522939682,\n",
       " -0.10201204568147659,\n",
       " -0.07249483466148376,\n",
       " -0.003024900099262595,\n",
       " -0.03118128329515457,\n",
       " 0.11694512516260147,\n",
       " -0.05732005089521408,\n",
       " 0.022682582959532738,\n",
       " -0.02275136299431324,\n",
       " 0.06624631583690643,\n",
       " 0.08006951212882996,\n",
       " -0.06961190700531006,\n",
       " -0.046753283590078354,\n",
       " 0.014536752365529537,\n",
       " 0.01752162165939808,\n",
       " 0.05432005971670151,\n",
       " 0.055380985140800476,\n",
       " 0.07079681754112244,\n",
       " 0.04330666735768318,\n",
       " 0.02344868890941143,\n",
       " 0.017352566123008728,\n",
       " -0.07405108958482742,\n",
       " 0.021884860470891,\n",
       " 0.03273164853453636,\n",
       " 0.001552868983708322,\n",
       " 0.03983812779188156,\n",
       " 0.05342577397823334,\n",
       " -0.03610844537615776]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize OpenAI embeddings with the latest model\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(\n",
    "   model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "## Example: create a embedding for a single text\n",
    "sample_text=\"What is machine learning\"\n",
    "sample_embedding=embeddings.embed_query(sample_text)\n",
    "sample_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476c19c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0365392304956913, -0.015164344571530819, 0.016432493925094604, 0.010568798519670963, 0.006010555662214756, -0.018473301082849503, 0.08546528965234756, 0.02096841111779213, 0.02781536430120468, 0.012431696057319641, -0.029376467689871788, -0.03113521635532379, 0.034912534058094025, -0.018150873482227325, -0.06498482078313828, 0.05168250948190689, -0.019606219604611397, -0.01573420688509941, -0.13371679186820984, -0.09645996242761612, -0.0254717618227005, -0.0014895654749125242, -0.006349365226924419, -0.025820661336183548, -0.02737182378768921, 0.12268996983766556, -0.007792486343532801, -0.03852272406220436, 0.014383514411747456, -0.09218423068523407, 0.008695718832314014, 0.00261337636038661, 0.09103468060493469, -0.030313612893223763, -0.09604636579751968, 0.022289138287305832, -0.09024309366941452, -0.0329473577439785, 0.0715833306312561, -0.008893118239939213, -0.025708945468068123, -0.07913962006568909, 0.014530369080603123, -0.07420428097248077, 0.08045009523630142, 0.07804084569215775, -0.012957030907273293, 0.019897066056728363, 0.011450350284576416, 0.051634229719638824, -0.12571601569652557, 0.011675041168928146, -0.04630652070045471, 0.003381346818059683, 0.005173508543521166, 0.028184255585074425, 0.023271549493074417, 0.004088610876351595, 0.008011849597096443, -0.017078513279557228, 0.0794496089220047, -0.05466397479176521, 0.025513896718621254, 0.03381358087062836, 0.09233345836400986, 0.02214878797531128, -0.018198711797595024, 0.0032429485581815243, -0.040028005838394165, -0.03808019682765007, 0.05245416611433029, 0.06670209765434265, -0.026317624375224113, 0.02363462746143341, 0.061881307512521744, -0.02636607177555561, 0.0406007282435894, -0.03885947912931442, 0.1213383749127388, -0.04354504123330116, -0.011664144694805145, -0.015057671815156937, -0.0397295281291008, 0.06364050507545471, 0.004621578846126795, 0.007112851832062006, 0.01947823353111744, 0.004021926783025265, 0.049122121185064316, 0.05309614911675453, -0.034766968339681625, -0.05722249299287796, 0.06325110048055649, 0.0004573104379232973, 0.03859065845608711, 0.07343205064535141, -0.0262956190854311, -0.11324034631252289, -0.06495114415884018, 0.20607666671276093, -0.03626524284482002, 0.029907509684562683, -0.055363476276397705, 0.008767406456172466, -0.02121807634830475, 0.008762290701270103, 0.028472939506173134, -0.034602582454681396, 0.04979703575372696, -0.018853971734642982, -0.04365286976099014, -0.025585683062672615, 0.017332717776298523, -0.011129291728138924, 0.032766830176115036, 0.035065241158008575, 0.05494406074285507, 0.10390885174274445, 0.04061216488480568, 0.02171243727207184, -0.02442539483308792, -0.005160624161362648, -0.009341873228549957, 0.10581018775701523, 0.045296598225831985, -0.03663654625415802, -0.044649917632341385, -5.240090799104761e-33, -0.049030765891075134, -0.04560507461428642, 0.06606081873178482, 0.0015988035593181849, 0.02337024174630642, -0.03394042328000069, -0.020720060914754868, -0.02059016190469265, -0.03648066148161888, -0.010393056087195873, -0.10783457010984421, 0.01680210418999195, -0.07954590022563934, 0.04248003661632538, 0.13682295382022858, 0.01094120740890503, 0.008169937878847122, 0.03037623129785061, -0.06491053849458694, -0.0070837209932506084, 0.028803128749132156, -0.03536086529493332, 0.0006857718108221889, -0.004703293554484844, -0.02408630959689617, 0.016173144802451134, 0.024679265916347504, -0.04610145837068558, 0.045457594096660614, 0.0008296648738905787, -0.003055521519854665, 0.07388895004987717, -0.05477891489863396, 0.0063984873704612255, -0.010182959958910942, -0.01362251304090023, -0.02577156387269497, -0.018861891701817513, 0.01854044944047928, 0.07305709272623062, -0.03451252356171608, 0.025277769193053246, 0.00011171410005772486, 0.010052131488919258, -0.014259378425776958, -0.0015917321434244514, 0.040022287517786026, -0.007197398226708174, -0.014384282752871513, -0.013920932076871395, -0.03563579171895981, 0.03647306188941002, 0.008935704827308655, -0.056835025548934937, 0.053594671189785004, -0.006161416415125132, -0.0217214934527874, 0.0337098054587841, -0.023625975474715233, -0.02035999298095703, 0.030925042927265167, 0.07569502294063568, -0.02297930419445038, 0.11616436392068863, -0.013501121662557125, 0.0491887703537941, 0.01098624151200056, 0.027952013537287712, 0.12113882601261139, 0.01650642417371273, -0.0509243905544281, -0.02870365045964718, 0.039391037076711655, 0.005959376227110624, -0.06095832958817482, 0.008872151374816895, -0.014630439691245556, -0.07118373364210129, -0.007659648545086384, -0.0735979899764061, -0.11550982296466827, -0.013440453447401524, -0.04058424010872841, 0.0004052826843690127, 0.03743290156126022, -0.036173172295093536, -0.026406511664390564, -0.038517311215400696, 0.018779361620545387, -0.010150980204343796, -0.08086315542459488, 0.01185519527643919, -0.022952014580368996, 0.058830492198467255, -0.07994716614484787, 4.626795356004449e-33, -0.07962002605199814, -0.03951388597488403, -0.06382591277360916, 0.08893607556819916, -0.0037363125011324883, -0.016144193708896637, -0.017867129296064377, -0.04251464456319809, 0.024427343159914017, 0.06664490699768066, -0.0578959658741951, -0.04232952371239662, 0.013483358547091484, 0.04562928155064583, 0.006878770422190428, -0.006714769639074802, 0.014821736142039299, -0.03707452863454819, -0.008778867311775684, 0.027316153049468994, -0.023431526497006416, 0.02286524698138237, -0.032763414084911346, -0.06674016267061234, -0.015621466562151909, 0.09837546944618225, -0.022562256082892418, 0.05578991025686264, -0.027223454788327217, 0.023654043674468994, 0.025091223418712616, -0.05378684401512146, -0.04549100250005722, 0.03996359184384346, 0.01017814688384533, 0.09332838654518127, 0.05655761808156967, -0.055691275745630264, -0.04962649568915367, 0.003937038592994213, 0.0525549054145813, -0.03237331658601761, -0.05560154840350151, 0.09626688808202744, -0.037710126489400864, -0.0018547856016084552, -0.040988095104694366, 0.09643054753541946, -0.0009849583730101585, -0.021389693021774292, -0.04590706527233124, 0.01615276373922825, -0.05922014266252518, -0.08145694434642792, -0.10162122547626495, 0.0024455352686345577, -0.014739121310412884, 0.014749213121831417, 0.0077285016886889935, 0.04645303636789322, -0.012513815425336361, -0.006437160074710846, -0.018233690410852432, 0.042206425219774246, -0.08553381264209747, 0.045899391174316406, 0.021831266582012177, 0.03515457361936569, 0.0015753180487081409, -0.03905198350548744, 0.13990840315818787, 0.01811697706580162, -0.027118170633912086, 0.07361293584108353, -0.035381436347961426, 0.0038902955129742622, -0.09528199583292007, 0.009677541442215443, -0.004546643700450659, -0.05977964773774147, -0.055846985429525375, -0.0856126993894577, -0.006143795792013407, 0.0746932178735733, -0.028714431449770927, 0.08817902952432632, 0.012425320222973824, -0.03300651162862778, -0.02849348820745945, 0.028219282627105713, -0.0009966152720153332, 0.049375634640455246, 0.0024040909484028816, 0.0009696028428152204, -0.1360941231250763, -1.2270175098194613e-08, -0.015120278112590313, -0.018518660217523575, 0.10543890297412872, 0.006514150183647871, 0.06480393558740616, 0.02293427102267742, -0.0632295086979866, 0.005378704518079758, -0.011222953908145428, -0.026959344744682312, -0.005579778458923101, -0.02042907103896141, 0.08938045799732208, 0.03170345723628998, 0.07528699934482574, -0.003716228296980262, -0.025884369388222694, 0.02160348743200302, -0.008521677926182747, -0.004489743150770664, 0.10893264412879944, -0.0013882283819839358, -0.040642786771059036, 0.008054756559431553, 0.012936677783727646, -0.06289546191692352, -0.003492692718282342, 0.03347349911928177, -0.04991278052330017, 0.11565355956554413, -0.0031069626566022635, 0.10181652009487152, 0.05068749561905861, -0.00920511968433857, 0.0669943317770958, 0.056775737553834915, 0.013960301876068115, -0.047010425478219986, -0.04209921509027481, -0.020429758355021477, -0.016778407618403435, 0.0902688205242157, 0.009978660382330418, -0.08400093764066696, 0.10684651136398315, 0.004483748693019152, -0.006322847679257393, -0.13133099675178528, 0.07453566044569016, -0.05268343910574913, -0.011863195337355137, 0.0022889375686645508, 0.03824467957019806, 0.12563945353031158, 0.11970926821231842, -0.009724888019263744, 0.011950534768402576, -0.03378896042704582, -0.034875594079494476, 0.08929368853569031, 0.11765249818563461, 0.049785465002059937, 0.048601485788822174, -0.06248895078897476]\n"
     ]
    }
   ],
   "source": [
    "texts=[\"AI\",\"MAchine learning\",\"Deep Learning\",\"Neural Network\"]\n",
    "batch_embeddings=embeddings.embed_documents(texts)\n",
    "print(batch_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce23d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.024391861632466316, 0.0032444545067846775, 0.05426763743162155, -0.00667257746681571, 0.00393569003790617, -0.007957367226481438, 0.02502524107694626, -0.03203275427222252, -0.05451072007417679, -0.04470203444361687, -0.013759422115981579, 0.016061270609498024, 0.040364738553762436, -0.02026093751192093, -0.06097462400794029, 0.02065557986497879, 0.010556329973042011, -0.01626482419669628, -0.10490719974040985, -0.11068311333656311, -0.021544726565480232, -0.013036089017987251, -0.0868835598230362, 0.027151895686984062, 0.026144085451960564, 0.039646606892347336, 0.06494352966547012, 0.06547265499830246, 0.0179632268846035, -0.10655660182237625, 0.009878258220851421, -0.03496198728680611, 0.03040347993373871, 0.014532738365232944, -0.1156027764081955, 0.012346150353550911, -0.06430959701538086, 0.04394596815109253, 0.019033178687095642, 0.030984850600361824, -0.015413855202496052, -0.0816345363855362, 0.012414447963237762, 0.012423722073435783, 0.06950360536575317, 0.07782550901174545, -0.003623040160164237, -0.012933368794620037, -0.03990815207362175, 0.04830601438879967, -0.09634712338447571, -0.014897680841386318, -0.033238157629966736, -0.01872224733233452, -0.06525663286447525, 0.03418876603245735, 0.015635060146450996, -0.01761307567358017, 0.04519093036651611, -0.003385143354535103, 0.05846893787384033, -0.08247902244329453, -0.08394177258014679, 0.009083951823413372, 0.11585061252117157, 0.007994660176336765, -0.007061520591378212, 0.06556662917137146, -0.0498260073363781, -0.06344430148601532, -0.03080609440803528, 0.03541972115635872, -0.03202145919203758, 0.04848283529281616, 0.06485569477081299, -0.02143756113946438, 0.038687337189912796, 0.03461192920804024, 0.08124350756406784, -0.027631573379039764, -0.05796577408909798, -0.005300167016685009, -0.038696080446243286, 0.06329432129859924, 0.0542885847389698, -0.013839186169207096, -0.03217106685042381, 0.025089705362915993, -0.026432527229189873, -0.0128270098939538, -0.01823446899652481, -0.017002644017338753, 0.048660822212696075, -0.05585087835788727, -0.08782372623682022, 0.06937871873378754, 0.0017591685755178332, -0.156575545668602, 0.025016991421580315, 0.23598122596740723, -0.05739317089319229, 0.03341679275035858, 0.004063507542014122, 0.0029722279869019985, 0.012201804667711258, -0.057148028165102005, 0.008463171310722828, -0.0008801552467048168, 0.0957709476351738, -0.11168898642063141, -0.06799851357936859, -0.018382098525762558, -0.0019815550185739994, -0.05596805363893509, 0.03777053579688072, -0.037008773535490036, 0.027574263513088226, -0.01317950151860714, -0.023938287049531937, 0.037316083908081055, -0.04417915269732475, -0.03197178989648819, 0.0034277813974767923, 0.07126101851463318, -0.02808738872408867, -0.06719307601451874, -0.061075493693351746, 3.4693638993327363e-34, -0.005817138124257326, -0.08467631042003632, -0.029431447386741638, 0.027067406103014946, 0.01720341108739376, -0.09422323107719421, 0.005866247229278088, -0.06413036584854126, 0.04407784715294838, 0.02057288959622383, -0.041366368532180786, 0.007860349491238594, 0.02564162015914917, -0.023032519966363907, 0.12271451205015182, -0.0032399536576122046, 0.039754729717969894, 0.11409460753202438, -0.02841002866625786, -0.023189084604382515, -0.018076423555612564, -0.023772181943058968, 0.06041106954216957, 0.003028752049431205, -0.027756541967391968, 0.022116517648100853, 0.021916421130299568, 0.0311601422727108, -0.037669241428375244, 0.029563412070274353, 0.06582330167293549, 0.020495297387242317, -0.027424855157732964, 0.006949577946215868, 0.05936912074685097, -0.01003754511475563, 0.005115820094943047, 0.030645029619336128, 0.06478002667427063, -0.013958386145532131, -0.07033707946538925, -0.060811497271060944, 0.07511109113693237, -0.012875588610768318, -0.02397092804312706, 0.04567629471421242, 0.029919905588030815, -0.06532847136259079, -0.04985169321298599, 0.009194471873342991, 0.015499225817620754, -0.02466130256652832, -0.04430844634771347, 0.02667267993092537, 0.03257698193192482, 0.11427278816699982, -0.029759418219327927, -0.003366330172866583, -0.012980670668184757, -0.03371134027838707, 0.09232016652822495, 0.03177569434046745, 0.011751600541174412, 0.028852319344878197, -0.032831594347953796, 0.0062039075419306755, 0.027960732579231262, -0.013924290426075459, 0.02341848611831665, 0.017485080286860466, -0.01003692764788866, -0.0031002932228147984, 0.06121155992150307, -0.05625142529606819, 0.036887988448143005, 0.043280016630887985, 0.025679398328065872, 0.054529234766960144, -0.05457066372036934, -0.0041092680767178535, -0.13821333646774292, -0.017061123624444008, 0.00394634110853076, -0.04147113114595413, 0.0038360317703336477, -0.056762490421533585, 0.022154968231916428, -0.04544428363442421, -0.030935131013393402, 0.052334513515233994, -0.11291738599538803, 0.06874144077301025, 0.04781147837638855, 0.0364174023270607, -0.057860735803842545, -8.327921971514963e-34, -0.13148143887519836, 0.03591359406709671, 0.06366762518882751, 0.11079368740320206, 0.022919030860066414, 0.020604807883501053, -0.040675029158592224, -0.040381401777267456, 0.005421176087111235, 0.0888499766588211, -0.012691110372543335, 0.026951927691698074, 0.06083172559738159, -0.0002634171978570521, -0.08807063847780228, 0.07137757539749146, 0.007459030020982027, -0.02990531362593174, -0.006546340882778168, 0.07382961362600327, -0.0402940958738327, 0.0526433028280735, -0.02247806079685688, -0.014469092711806297, -0.004329350311309099, 0.004191316664218903, -0.018816495314240456, 0.015351926907896996, -0.05584387481212616, -0.046583279967308044, -0.015183358453214169, -0.03867322951555252, -0.04416891559958458, 0.053726475685834885, -0.05850518122315407, 0.03006473369896412, -0.0024193660356104374, 0.019356384873390198, 0.005732525140047073, 0.10568251460790634, 0.03650883212685585, 0.051057249307632446, -0.10807374119758606, 0.03211061283946037, -0.029158197343349457, -0.10622183233499527, -0.06207776069641113, 0.022346433252096176, 0.06606440246105194, -0.03970411792397499, -0.032181259244680405, 0.05124160274863243, -0.015171539038419724, -0.06061473488807678, -0.021133698523044586, 0.02760552428662777, -0.028027575463056564, -0.038763463497161865, 0.021921435371041298, 0.0550958514213562, -0.1318366378545761, -0.0534481443464756, 0.015804989263415337, 0.08465718477964401, 0.006558409426361322, -0.01612083613872528, -0.028955113142728806, 0.04573335498571396, -0.035446662455797195, 0.015917684882879257, 0.07113125920295715, 0.06012149155139923, -0.012370919808745384, 0.011201624758541584, -0.01618109829723835, -0.042452212423086166, -0.07842529565095901, -0.039063844829797745, -0.03729779273271561, -0.040253859013319016, 0.030674781650304794, -0.05714095011353493, 0.029395800083875656, 0.08310706168413162, 0.019608091562986374, 0.055219538509845734, 0.09535323828458786, -0.014108852483332157, 0.033667951822280884, -0.056696414947509766, -0.012401449494063854, 0.03735920786857605, -0.003296448150649667, 0.01161134708672762, -0.05470046401023865, -1.4752097321490965e-08, -0.027424825355410576, -0.07633443921804428, 0.08716373145580292, -0.0024674523156136274, 0.05077929049730301, 0.04894988238811493, -0.06277710199356079, 0.0861940011382103, -0.028905346989631653, 0.006605516653507948, 0.033771563321352005, 0.020471664145588875, -0.027950404211878777, 0.06820963323116302, -0.015135511755943298, 0.007914411835372448, -0.02251039631664753, 0.06165093556046486, -0.024779759347438812, 0.013340074568986893, 0.08776803314685822, 0.06991861015558243, 0.04617294669151306, 0.010393407195806503, 0.10544244945049286, -0.05000018700957298, 0.01867702603340149, 0.06655582040548325, 0.02177313342690468, 0.06218167766928673, -0.03119920939207077, 0.09787546843290329, 0.02689552679657936, -0.018385019153356552, 0.10476367175579071, 0.08063986897468567, 0.009436028078198433, -0.07085257768630981, -0.025755595415830612, 0.041329577565193176, -0.029373135417699814, 0.03996405377984047, -0.08191832900047302, -0.028407074511051178, 0.025465426966547966, 0.017960693687200546, 0.04338834062218666, -0.1254221349954605, 0.029067512601614, -0.004652839154005051, 0.04126804322004318, 0.041181210428476334, 0.049320343881845474, 0.03235520422458649, 0.0187042485922575, 0.057700395584106445, 0.050881221890449524, -0.034820087254047394, -0.0009677863563410938, 0.022412003949284554, 0.040253251791000366, 0.03536273539066315, -0.021799152716994286, -0.05384537950158119]\n"
     ]
    }
   ],
   "source": [
    "print(batch_embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4452d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare Embedding using cosine similarity\n",
    "\n",
    "def compare_embeddings(text1:str,text2:str):\n",
    "    \"\"\"Compare semantic simialrity of 2 texts usign embeddings\"\"\"\n",
    "\n",
    "    emb1=np.array(embeddings.embed_query(text1))\n",
    "    emb2=np.array(embeddings.embed_query(text2))\n",
    "\n",
    "    ## Calculate the simialrity score\n",
    "\n",
    "    similarity=np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d2e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic Similarity Examples:\n",
      "'AI' vs 'Artificial Intelligence': 0.791\n"
     ]
    }
   ],
   "source": [
    "# Test semantic similarity\n",
    "print(\"\\nSemantic Similarity Examples:\")\n",
    "print(f\"'AI' vs 'Artificial Intelligence': {compare_embeddings('AI', 'Artificial Intelligence'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ea6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AI' vs 'Pizza': 0.257\n"
     ]
    }
   ],
   "source": [
    "print(f\"'AI' vs 'Pizza': {compare_embeddings('AI', 'Pizza'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50296f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Machine Learning' vs 'ML': 0.373\n"
     ]
    }
   ],
   "source": [
    "print(f\"'Machine Learning' vs 'ML': {compare_embeddings('Machine Learning', 'ML'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9735ac2",
   "metadata": {},
   "source": [
    "### Create FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0989a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 4 vectors\n"
     ]
    }
   ],
   "source": [
    "vectorstore=FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "print(f\"Vector store created with {vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32d15527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2592df28ad0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0d43809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store saved to 'faiss_index' directory\n"
     ]
    }
   ],
   "source": [
    "## Save vector tore for later use\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "print(\"Vector store saved to 'faiss_index' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dd954a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vector store contains 4 vectors\n"
     ]
    }
   ],
   "source": [
    "## load vector store\n",
    "loaded_vectorstore=FAISS.load_local(\n",
    "    \"faiss_index\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(f\"Loaded vector store contains {loaded_vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca90941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='acaaed55-1811-4986-a526-598f29e15135', metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'DL'}, page_content='Deep Learning is a subset of machine learning based on artificial neural networks.\\n        It uses multiple layers to progressively extract higher-level features from raw input.\\n        Deep learning has revolutionized computer vision, NLP, and speech recognition.'), Document(id='b2ef85a0-b650-454e-9606-1dbfe1dc5bf7', metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.'), Document(id='333b873f-463e-417c-9f9f-b7008b52afa2', metadata={'source': 'NLP Overview', 'page': 1, 'topic': 'NLP'}, page_content='Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\\n        It combines computational linguistics with machine learning and deep learning models.\\n        Applications include chatbots, translation, sentiment analysis, and text summarization.')]\n"
     ]
    }
   ],
   "source": [
    "## Similarity Search \n",
    "query=\"What is deep learning\"\n",
    "\n",
    "results=vectorstore.similarity_search(query,k=3)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b21fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is deep learning\n",
      "\n",
      "Top 3 similar chunks:\n",
      "\n",
      "1. Source: Deep Learning\n",
      "   Content: Deep Learning is a subset of machine learning based on artificial neural networks.\n",
      "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
      "        Deep learning ...\n",
      "\n",
      "2. Source: ML Basics\n",
      "   Content: Machine Learning is a subset of AI that enables systems to learn from data.\n",
      "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
      "        Common types include supervised...\n",
      "\n",
      "3. Source: NLP Overview\n",
      "   Content: Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
      "        It combines computational linguistics with machine learning and deep learning models.\n",
      "      ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Top 3 similar chunks:\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n{i+1}. Source: {doc.metadata['source']}\")\n",
    "    print(f\"   Content: {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0234314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Similarity search with scores:\n",
      "\n",
      "Score: 0.343\n",
      "Source: Deep Learning\n",
      "Content preview: Deep Learning is a subset of machine learning based on artificial neural networks.\n",
      "        It uses m...\n",
      "\n",
      "Score: 1.090\n",
      "Source: ML Basics\n",
      "Content preview: Machine Learning is a subset of AI that enables systems to learn from data.\n",
      "        Instead of being...\n",
      "\n",
      "Score: 1.154\n",
      "Source: NLP Overview\n",
      "Content preview: Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "### Similarity Search with score\n",
    "results_with_scores=vectorstore.similarity_search_with_score(query,k=3)\n",
    "\n",
    "print(\"\\n\\nSimilarity search with scores:\")\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"\\nScore: {score:.3f}\")\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Content preview: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23a80f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}, page_content='Artificial Intelligence (AI) is the simulation of human intelligence in machines.\\n        These systems are designed to think like humans and mimic their actions.\\n        AI can be categorized into narrow AI and general AI.'),\n",
       " Document(metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.'),\n",
       " Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'DL'}, page_content='Deep Learning is a subset of machine learning based on artificial neural networks.\\n        It uses multiple layers to progressively extract higher-level features from raw input.\\n        Deep learning has revolutionized computer vision, NLP, and speech recognition.'),\n",
       " Document(metadata={'source': 'NLP Overview', 'page': 1, 'topic': 'NLP'}, page_content='Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\\n        It combines computational linguistics with machine learning and deep learning models.\\n        Applications include chatbots, translation, sentiment analysis, and text summarization.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46e0d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='b2ef85a0-b650-454e-9606-1dbfe1dc5bf7', metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.')]\n"
     ]
    }
   ],
   "source": [
    "### Search with metadata filtering\n",
    "filter_dict={\"topic\":\"ML\"}\n",
    "filtered_results=vectorstore.similarity_search(\n",
    "    query,\n",
    "    k=3,\n",
    "    filter=filter_dict\n",
    ")\n",
    "print(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f153009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3214a1d",
   "metadata": {},
   "source": [
    "### Build RAG Chain With LCEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d6de908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002594E914C90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002594E90C090>, model_name='openai/gpt-oss-20b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LLM GROQ LLM\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=init_chat_model(model=\"groq:openai/gpt-oss-20b\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c28e9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! 👋 How can I help you today?', additional_kwargs={'reasoning_content': 'We need to respond to the user greeting. We are ChatGPT. Should keep tone friendly, ask what they need.'}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 72, 'total_tokens': 117, 'completion_time': 0.044317914, 'prompt_time': 0.003348443, 'queue_time': 0.048507367, 'total_time': 0.047666357}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_80501ff3a1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--8e40cab0-4039-4b95-8f20-c89254c48716-0', usage_metadata={'input_tokens': 72, 'output_tokens': 45, 'total_tokens': 117})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26844d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Simple RAG Chain with LCEL\n",
    "simple_prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question based only on the following context:\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f83433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic retriever\n",
    "retriever=vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d35a9fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002592DF28AD0>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3db5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "# Format documents for the prompt\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    \"\"\"Format documents for insertion into prompt\"\"\"\n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        formatted.append(f\"Document {i+1} (Source: {source}):\\n{doc.page_content}\")\n",
    "    return \"\\n\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c6f65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rag_chain=(\n",
    "    {\"context\":retriever | format_docs,\"question\":RunnablePassthrough() }\n",
    "    | simple_prompt\n",
    "    | llm\n",
    "    |StrOutputParser()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c470a6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002592DF28AD0>, search_kwargs={'k': 3})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\nContext: {context}\\n\\nQuestion: {question}\\n\\nAnswer:'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002594E914C90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002594E90C090>, model_name='openai/gpt-oss-20b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18098855",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conversational RAg Chain\n",
    "\n",
    "conversational_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant. Use the provided context to answer questions.\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"human\", \"Context: {context}\\n\\nQuestion: {input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c42689e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversational_rag():\n",
    "    \"\"\"Create a conversational RAG chain with memory\"\"\"\n",
    "    return (\n",
    "        RunnablePassthrough.assign(\n",
    "            context=lambda x: format_docs(retriever.invoke(x[\"input\"]))\n",
    "        )\n",
    "        | conversational_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "conversational_rag = create_conversational_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f255f6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  context: RunnableLambda(lambda x: format_docs(retriever.invoke(x['input'])))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002597892F7E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assistant. Use the provided context to answer questions.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='Context: {context}\\n\\nQuestion: {input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002594E914C90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002594E90C090>, model_name='openai/gpt-oss-20b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c88574dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modern RAG chains created successfully!\n",
      "Available chains:\n",
      "- simple_rag_chain: Basic Q&A\n",
      "- conversational_rag: Maintains conversation history\n",
      "- streaming_rag_chain: Supports token streaming\n"
     ]
    }
   ],
   "source": [
    "### streaming RAG chain\n",
    "streaming_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | simple_prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "print(\"Modern RAG chains created successfully!\")\n",
    "print(\"Available chains:\")\n",
    "print(\"- simple_rag_chain: Basic Q&A\")\n",
    "print(\"- conversational_rag: Maintains conversation history\")\n",
    "print(\"- streaming_rag_chain: Supports token streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d8a26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function for different chain types\n",
    "def test_rag_chains(question: str):\n",
    "    \"\"\"Test all RAG chain variants\"\"\"\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Simple RAG\n",
    "    print(\"\\n1. Simple RAG Chain:\")\n",
    "    answer = simple_rag_chain.invoke(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "    print(\"\\n2. Streaming RAG:\")\n",
    "    print(\"Answer: \", end=\"\", flush=True)\n",
    "    for chunk in streaming_rag_chain.stream(question):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5a9cd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the difference between AI and machine learning\n",
      "================================================================================\n",
      "\n",
      "1. Simple RAG Chain:\n",
      "Answer: AI is the broader field that encompasses any system designed to simulate human intelligence—thinking, reasoning, and mimicking human actions. Machine learning is a specific subset of AI that focuses on algorithms that learn patterns from data instead of being explicitly programmed. In short, all machine‑learning systems are AI, but not all AI systems use machine learning.\n",
      "\n",
      "2. Streaming RAG:\n",
      "Answer: AI is the broader field that covers any technique that simulates or mimics human intelligence, such as rule‑based systems, symbolic reasoning, and other approaches.  \n",
      "Machine learning is a specific subset of AI that focuses on algorithms that learn patterns from data rather than being explicitly programmed. Thus, all machine learning is AI, but not all AI is machine learning.\n"
     ]
    }
   ],
   "source": [
    "test_rag_chains(\"What is the difference between AI and machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5e375d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What is the difference between AI and Machine Learning?\n",
      "================================================================================\n",
      "\n",
      "1. Simple RAG Chain:\n",
      "Answer: AI is the broader concept of machines performing tasks that typically require human intelligence, while Machine Learning is a specific subset of AI that allows systems to learn from data without explicit programming.  \n",
      "\n",
      "\n",
      "2. Streaming RAG:\n",
      "Answer: Artificial Intelligence (AI) is the broad concept of machines simulating human intelligence, while Machine Learning (ML) is a subset of AI that focuses on enabling systems to learn from data without explicit programming.  \n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: Explain deep learning in simple terms\n",
      "================================================================================\n",
      "\n",
      "1. Simple RAG Chain:\n",
      "Answer: Deep learning is a type of machine learning that uses artificial networks with many layers to learn from data.  Think of it like teaching a computer to recognize patterns, like pictures or words, by showing it lots of examples. Each layer in the network helps it learn more complex features, ultimately allowing it to make accurate predictions. \n",
      "\n",
      "\n",
      "2. Streaming RAG:\n",
      "Answer: Deep learning is a type of machine learning that uses many layers of artificial neurons to learn complex patterns from data.  It's like teaching a computer to see and understand things the way humans do, by showing it lots of examples.  Deep learning has been especially successful in areas like computer vision (recognizing objects in images), natural language processing (understanding and generating text), and speech recognition. \n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: How does NLP work?\n",
      "================================================================================\n",
      "\n",
      "1. Simple RAG Chain:\n",
      "Answer: NLP combines computational linguistics with machine learning and deep learning models.  \n",
      "\n",
      "\n",
      "2. Streaming RAG:\n",
      "Answer: NLP combines computational linguistics with machine learning and deep learning models.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple questions\n",
    "test_questions = [\n",
    "    \"What is the difference between AI and Machine Learning?\",\n",
    "    \"Explain deep learning in simple terms\",\n",
    "    \"How does NLP work?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "    test_rag_chains(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afcfe3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Conversational RAG Example:\n",
      "Q1: What is machine learning?\n",
      "A1: Machine learning (ML) is a branch of artificial intelligence that empowers systems to learn from data rather than being explicitly programmed for every task. By feeding input data into ML algorithms, the system automatically discovers patterns, relationships, and rules that can be used to make predictions or decisions. Common ML paradigms include:\n",
      "\n",
      "- **Supervised learning** – learning from labeled examples.  \n",
      "- **Unsupervised learning** – discovering structure in unlabeled data.  \n",
      "- **Reinforcement learning** – learning by trial and error through rewards and penalties.\n",
      "\n",
      "In short, ML lets computers improve their performance on a task simply by being exposed to more data.\n"
     ]
    }
   ],
   "source": [
    "## Conversational example\n",
    "print(\"\\n3. Conversational RAG Example:\")\n",
    "chat_history = []\n",
    "\n",
    "# First question\n",
    "q1 = \"What is machine learning?\"\n",
    "a1 = conversational_rag.invoke({\n",
    "    \"input\": q1,\n",
    "    \"chat_history\": chat_history\n",
    "})\n",
    "\n",
    "print(f\"Q1: {q1}\")\n",
    "print(f\"A1: {a1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3a72dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update history\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=q1),\n",
    "    AIMessage(content=a1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b9eda39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q2: How is it different from traditional programming?\n",
      "A2: **Key difference between machine learning (ML) and traditional programming**\n",
      "\n",
      "| Aspect | Traditional Programming | Machine Learning |\n",
      "|--------|------------------------|------------------|\n",
      "| **How it works** | You write explicit, step‑by‑step instructions (rules) that tell the computer exactly what to do. | You provide data and let the algorithm discover patterns and rules on its own. |\n",
      "| **Input‑to‑Output mapping** | The mapping is defined by the programmer’s code. | The mapping is inferred from examples in the data. |\n",
      "| **Adaptability** | To change behavior you must modify the code and re‑deploy. | The model can be retrained on new data to adapt automatically. |\n",
      "| **Scope of problems** | Best for problems that can be fully described by deterministic rules (e.g., arithmetic, formatting). | Excels at problems with complex, high‑dimensional, or noisy data (e.g., image recognition, speech, natural language). |\n",
      "| **Example from documents** | Traditional programming follows the *simulation of human intelligence* approach described in **Document 2** – you explicitly code the logic for each task. | ML, as defined in **Document 1**, “enables systems to learn from data” and “find patterns in data” without hard‑coding each rule. |\n",
      "\n",
      "In short, traditional programming is **rule‑based** and **static**: the programmer writes the logic once. Machine learning is **data‑driven** and **dynamic**: the system learns the logic from examples, and can improve or change its behavior as more data becomes available.\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question\n",
    "q2 = \"How is it different from traditional programming?\"\n",
    "a2 = conversational_rag.invoke({\n",
    "    \"input\": q2,\n",
    "    \"chat_history\": chat_history\n",
    "})\n",
    "print(f\"\\nQ2: {q2}\")\n",
    "print(f\"A2: {a2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ada94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
